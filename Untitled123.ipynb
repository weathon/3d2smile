{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weathon/3d2smile/blob/main/Untitled123.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n20yIuGF5afw"
      },
      "outputs": [],
      "source": [
        "!pip install transformers -U\n",
        "!pip install tqdm boto3 requests regex sentencepiece sacremoses huggingface_hub\n",
        "!pip install wandb\n",
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_ktT69Sv4Iki"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from rdkit import Chem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MzzAzcWx4zYw"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"SMRT_dataset.csv\", sep=\";\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Np8VMwEbT2uq"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv(\"name.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "17AMumCMSiGn"
      },
      "outputs": [],
      "source": [
        "with open(\"pid\",\"w\") as f:\n",
        "  f.write(\"\\n\".join([str(i) for i in list(df[\"pubchem\"])]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnCL7WCW5FnM",
        "outputId": "08e12b2a-efea-4a95-ad38-7bb98268eca8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_main\n"
          ]
        }
      ],
      "source": [
        "smiles_encoder = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert--uncasbaseed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "23isgOJgj_H6"
      },
      "outputs": [],
      "source": [
        "smiles_encoder.encoder.layer=smiles_encoder.encoder.layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RfaEbl2o7jAv"
      },
      "outputs": [],
      "source": [
        "# smiles_arr = list(df2[\"isosmiles\"][df[\"pubchem\"]])\n",
        "smiles_arr = []\n",
        "for i in list(df[\"pubchem\"]):\n",
        "  smiles_arr.append(df2[df2[\"cid\"]==i][\"isosmiles\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(smiles_arr)):\n",
        "  Chem.MolFromSmiles(smiles_arr[i])"
      ],
      "metadata": {
        "id": "SvUhba_zHIzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NfIjoXqwWsYO"
      },
      "outputs": [],
      "source": [
        "smiles_arr = [i.item() if len(i)==1 else \"\" for i in smiles_arr]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ATM--TJN7fEo"
      },
      "outputs": [],
      "source": [
        "chars = list(set(\"\".join(smiles_arr)))\n",
        "tokens = dict.fromkeys(chars)\n",
        "for i, char in enumerate(chars):\n",
        "  tokens[char] = i\n",
        "reversed_mapping = {}\n",
        "for i, char in enumerate(chars):\n",
        "  reversed_mapping[i] = char\n",
        "for i, smiles in enumerate(smiles_arr):\n",
        "  smiles_arr[i] = [tokens[char] for char in smiles]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pI9d6-7uAJXi"
      },
      "outputs": [],
      "source": [
        "chars.append(\"<CLS>\")\n",
        "CLS = chars.index(\"<CLS>\")\n",
        "smiles_arr = [[CLS]+i for i in smiles_arr]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lG8jdA0ECq2R"
      },
      "outputs": [],
      "source": [
        "padding = len(chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Y-8irptkCTGP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda:0')\n",
        "else:\n",
        "  device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "u31DBBKCAJzt"
      },
      "outputs": [],
      "source": [
        "# https://youtu.be/ug8YvZOjOCE?t=2692\n",
        "class CL(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.smiles_encoder = smiles_encoder.to(device)\n",
        "    self.mlp = torch.nn.Sequential(torch.nn.Linear(768, 384),\n",
        "                                    torch.nn.ReLU(),\n",
        "                                    torch.nn.Linear(384, 192),\n",
        "                                    torch.nn.ReLU(),\n",
        "                                    torch.nn.Linear(192, 96),\n",
        "                                    torch.nn.ReLU(),\n",
        "                                    torch.nn.Linear(96, 1),\n",
        "                                    torch.nn.ReLU(),\n",
        "                                   )\n",
        "\n",
        "  def forward(self, smiles):\n",
        "    seq = self.smiles_encoder(smiles, attention_mask=(smiles!=padding)).last_hidden_state\n",
        "    out = self.mlp(seq[:,0,:])\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6NrsfUggcSyb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9cVN2QSmHD7T"
      },
      "outputs": [],
      "source": [
        "def pad(strs):\n",
        "  maxlen = max([len(i) for i in strs])\n",
        "  for i in range(len(strs)):\n",
        "    strs[i] += [padding] * (maxlen - len(strs[i]))\n",
        "  return np.array(list(strs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7JAFYcfLLZM",
        "outputId": "5a5f163a-57c5-458d-f546-9012d9aa5b4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwguo6358\u001b[0m (\u001b[33m3dsmile\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "pB10KKOfLYhk",
        "outputId": "508f8138-f4cb-4f2c-8a0c-ea4dc7d18948"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231225_062418-e5h3syul</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/3dsmile/my-awesome-project/runs/e5h3syul' target=\"_blank\">comfy-snowball-63</a></strong> to <a href='https://wandb.ai/3dsmile/my-awesome-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/3dsmile/my-awesome-project' target=\"_blank\">https://wandb.ai/3dsmile/my-awesome-project</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/3dsmile/my-awesome-project/runs/e5h3syul' target=\"_blank\">https://wandb.ai/3dsmile/my-awesome-project/runs/e5h3syul</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "run = wandb.init(\n",
        "    project=\"my-awesome-project\",\n",
        "    config={\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6syoFB_L_E2",
        "outputId": "68afec07-df23-4c04-9b8a-653361eade31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-e80ad98e3288>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  smiles_arr = np.array(smiles_arr)[:-100]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "model = CL().to(device)\n",
        "df[\"rt\"] = df[\"rt\"]/(max(df[\"rt\"])/10)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00002)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.995)\n",
        "smiles_arr = np.array(smiles_arr)[:-100]\n",
        "RT = np.array(list(df[\"rt\"]))[:-100]\n",
        "\n",
        "smiles_arr_val = np.array(smiles_arr)[-100:]\n",
        "RT_val = np.array(list(df[\"rt\"]))[-100:]\n",
        "\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "slices = list(range(0, (len(RT)), BATCH_SIZE))\n",
        "slices.append(-1)\n",
        "\n",
        "slices_val = list(range(0, (len(RT_val)), BATCH_SIZE))\n",
        "slices_val.append(-1)\n",
        "\n",
        "losses = []\n",
        "val_loss = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ElDz206hCEJ",
        "outputId": "85c37236-62bf-4164-9e7c-e3901046ebe5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80038"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8apVU_YwGB5w",
        "outputId": "b4bfd71a-7e9c-46d0-f732-266dcf3a046f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new lr\n",
            "new lr\n",
            "new lr\n",
            "new lr\n",
            "new lr\n",
            "new lr\n",
            "new lr\n",
            "new lr\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(30):\n",
        "  indices = np.arange(len(RT))\n",
        "  np.random.shuffle(indices)\n",
        "  smiles_arr = smiles_arr[indices]\n",
        "  RT = RT[indices]\n",
        "  running_loss = 0\n",
        "  for i in range(len(slices)-1):\n",
        "    X_1 = torch.tensor(pad(smiles_arr[slices[i]:slices[i+1]])).to(device)\n",
        "    Y = torch.tensor(RT[slices[i]:slices[i+1]]).to(device).unsqueeze(-1).to(torch.float32)\n",
        "    optimizer.zero_grad()\n",
        "    predicted = model(X_1)\n",
        "    loss = torch.nn.functional.mse_loss(predicted, Y)\n",
        "    # losses.append(loss.cpu())\n",
        "    running_loss+=loss.cpu()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if i%500==500-1:\n",
        "      print(\"new lr\")\n",
        "      wandb.log({\"loss\":running_loss/500,  \"lr\":optimizer.param_groups[0][\"lr\"]})\n",
        "      scheduler.step()\n",
        "      running_loss=0\n",
        "\n",
        "  # validation\n",
        "  running_loss = []\n",
        "  for i in range(len(slices_val)-1):\n",
        "    X_1 = torch.tensor(pad(smiles_arr_val[slices_val[i]:slices_val[i+1]])).to(device)\n",
        "    Y = torch.tensor(RT_val[slices_val[i]:slices_val[i+1]]).to(device).unsqueeze(-1).to(torch.float32)\n",
        "    predicted = model(X_1)\n",
        "    loss = torch.nn.functional.mse_loss(predicted, Y)\n",
        "    running_loss.append(loss.cpu().item())\n",
        "  val_loss.append(np.mean(running_loss))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "52EHY8kso2xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqO-_YKXFDUG"
      },
      "outputs": [],
      "source": [
        "scheduler.step()\n",
        "scheduler.step()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7VsGnHVvWkIbAOK3zFBmN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}