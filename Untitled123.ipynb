{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weathon/3d2smile/blob/main/Untitled123.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n20yIuGF5afw",
        "outputId": "3dff01b5-ec1f-4dd2-895b-60a3b54accdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.36.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (1.34.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (2023.6.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.19.4)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.7 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.34.7)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3) (0.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.11.17)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.7->boto3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.7->boto3) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers -U\n",
        "!pip install tqdm boto3 requests regex sentencepiece sacremoses huggingface_hub\n",
        "!pip install wandb\n",
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ktT69Sv4Iki"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from rdkit import Chem\n",
        "from rdkit import DataStructs\n",
        "from rdkit.Chem import AllChem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzzAzcWx4zYw"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"SMRT_dataset.csv\", sep=\";\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Np8VMwEbT2uq"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv(\"name.csv\")\n",
        "df2 = df2[[\"isosmiles\",\"cid\"]]\n",
        "# df2.to_csv(\"name.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17AMumCMSiGn"
      },
      "outputs": [],
      "source": [
        "with open(\"pid\",\"w\") as f:\n",
        "  f.write(\"\\n\".join([str(i) for i in list(df[\"pubchem\"])]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnCL7WCW5FnM"
      },
      "outputs": [],
      "source": [
        "smiles_encoder = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23isgOJgj_H6"
      },
      "outputs": [],
      "source": [
        "smiles_encoder.encoder.layer=smiles_encoder.encoder.layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfaEbl2o7jAv"
      },
      "outputs": [],
      "source": [
        "# smiles_arr = list(df2[\"isosmiles\"][df[\"pubchem\"]])\n",
        "smiles_arr = []\n",
        "for i in list(df[\"pubchem\"]):\n",
        "  smiles_arr.append(df2[df2[\"cid\"]==i][\"isosmiles\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfIjoXqwWsYO"
      },
      "outputs": [],
      "source": [
        "smiles_arr = [i.item() if len(i)==1 else \"\" for i in smiles_arr]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_gjHemSJAvL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "fpgen = AllChem.GetRDKitFPGenerator()\n",
        "fps = []\n",
        "for i in smiles_arr[:200]:\n",
        "  a = (fpgen.GetFingerprint(Chem.MolFromSmiles(i)))\n",
        "  fps.append(np.array(a))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pi6NiKda0FA1"
      },
      "outputs": [],
      "source": [
        "del smiles_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-8irptkCTGP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda:0')\n",
        "else:\n",
        "  device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVpO2M4X-AU7"
      },
      "outputs": [],
      "source": [
        "padding = len(a)+1\n",
        "CLS = len(a)+2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZIPysv8ViJr"
      },
      "outputs": [],
      "source": [
        "fps = [np.where(i==1) for i in fps]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u31DBBKCAJzt"
      },
      "outputs": [],
      "source": [
        "# https://youtu.be/ug8YvZOjOCE?t=2692\n",
        "class CL(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.embeding = torch.nn.Embedding(len(a)+2, 512, padding)\n",
        "    self.transformers = torch.nn.Sequential(\n",
        "        torch.nn.TransformerEncoderLayer(512, 8, batch_first=True),\n",
        "        torch.nn.TransformerEncoderLayer(512, 8, batch_first=True),\n",
        "        torch.nn.TransformerEncoderLayer(512, 8, batch_first=True),\n",
        "        torch.nn.TransformerEncoderLayer(512, 8, batch_first=True),\n",
        "        torch.nn.TransformerEncoderLayer(512, 8, batch_first=True),\n",
        "        torch.nn.TransformerEncoderLayer(512, 8, batch_first=True),\n",
        "    )\n",
        "    self.mlp = torch.nn.Sequential(\n",
        "        torch.nn.Linear(512, 64),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(64, 32),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(32, 1),\n",
        "        torch.nn.ReLU(),\n",
        "    )\n",
        "  def forward(self, smiles):\n",
        "    return self.mlp(self.transformers(self.embeding(smiles))[:,0,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7JAFYcfLLZM"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pB10KKOfLYhk"
      },
      "outputs": [],
      "source": [
        "run = wandb.init(\n",
        "    project=\"my-awesome-project\",\n",
        "    config={\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csHQjBkg6iv0"
      },
      "outputs": [],
      "source": [
        "fps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6syoFB_L_E2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "model = CL()#.to(device)\n",
        "df[\"rt\"] = df[\"rt\"]/(max(df[\"rt\"]))\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00003)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.995)\n",
        "\n",
        "fps_val = np.array(fps)[:-100]\n",
        "RT_val = np.array(list(df[\"rt\"]))[:-100]\n",
        "\n",
        "fps = np.array(fps)[-100:]\n",
        "RT = np.array(list(df[\"rt\"]))[-100:]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "slices = list(range(0, (len(RT)), BATCH_SIZE))\n",
        "slices.append(-1)\n",
        "\n",
        "slices_val = list(range(0, (len(RT_val)), BATCH_SIZE))\n",
        "slices_val.append(-1)\n",
        "\n",
        "losses = []\n",
        "val_loss = []"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "8Nomqv-7OY68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ElDz206hCEJ"
      },
      "outputs": [],
      "source": [
        "fps = [i[0] for i in fps]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dIF6bWzc9c-"
      },
      "outputs": [],
      "source": [
        "fps = np.array(fps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ajka9kIZnhzQ"
      },
      "outputs": [],
      "source": [
        "def pad(strs):\n",
        "  # print(strs)\n",
        "  maxlen = max([len(i) for i in strs])+1\n",
        "  strs = [[CLS]+list(i) for i in strs]\n",
        "  for i in range(len(strs)):\n",
        "    strs[i] += [padding] * (maxlen - len(strs[i]))\n",
        "  return np.array(list(strs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jn-GWzqC0zdH"
      },
      "outputs": [],
      "source": [
        "model(torch.tensor(pad([[1,2,3],[1]])).to(device))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "slices"
      ],
      "metadata": {
        "id": "D4zU0o8fU--U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fps.shape"
      ],
      "metadata": {
        "id": "IlKBnH9zVCcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8apVU_YwGB5w"
      },
      "outputs": [],
      "source": [
        "for epoch in range(30):\n",
        "  indices = np.arange(len(fps))\n",
        "  np.random.shuffle(indices)\n",
        "  fps = fps[indices]\n",
        "  RT = RT[indices]\n",
        "  running_loss = 0\n",
        "  for i in range(len(slices)-1):\n",
        "    X_1 = torch.tensor(pad(fps[slices[i]:slices[i+1]])).to(device)\n",
        "    Y = torch.tensor(RT[slices[i]:slices[i+1]]).to(device).unsqueeze(-1).to(torch.float32)\n",
        "    optimizer.zero_grad()\n",
        "    predicted = model(X_1)\n",
        "    loss = torch.nn.functional.mse_loss(predicted, Y)\n",
        "    # losses.append(loss.cpu())\n",
        "    running_loss+=loss.cpu()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if i%30==30-1:\n",
        "      print(\"new lr\")\n",
        "      wandb.log({\"loss\":running_loss/30,  \"lr\":optimizer.param_groups[0][\"lr\"]})\n",
        "      scheduler.step()\n",
        "      running_loss=0\n",
        "\n",
        "  # validation\n",
        "  running_loss = []\n",
        "  for i in range(len(slices_val)-1):\n",
        "    X_1 = torch.tensor(pad(fps_val[slices_val[i]:slices_val[i+1]])).to(device)\n",
        "    Y = torch.tensor(RT_val[slices_val[i]:slices_val[i+1]]).to(device).unsqueeze(-1).to(torch.float32)\n",
        "    predicted = model(X_1)\n",
        "    loss = torch.nn.functional.mse_loss(predicted, Y)\n",
        "    running_loss.append(loss.cpu().item())\n",
        "  val_loss.append(np.mean(running_loss))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJSiqDnSX/AwiE/uX1Jc1D",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}