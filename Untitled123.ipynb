{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weathon/3d2smile/blob/main/Untitled123.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n20yIuGF5afw"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers -U\n",
        "# !pip install tqdm boto3 requests regex sentencepiece sacremoses huggingface_hub\n",
        "# !pip install wandb\n",
        "# !pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_ktT69Sv4Iki"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from rdkit import Chem\n",
        "from rdkit import DataStructs\n",
        "from rdkit.Chem import AllChem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MzzAzcWx4zYw"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"SMRT_dataset.csv\", sep=\";\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Np8VMwEbT2uq"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv(\"name.csv\")\n",
        "df2 = df2[[\"isosmiles\",\"cid\"]]\n",
        "# df2.to_csv(\"name.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "17AMumCMSiGn"
      },
      "outputs": [],
      "source": [
        "with open(\"pid\",\"w\") as f:\n",
        "  f.write(\"\\n\".join([str(i) for i in list(df[\"pubchem\"])]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnCL7WCW5FnM",
        "outputId": "8c915700-fe32-4bf3-d07c-026a4a712722"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_main\n"
          ]
        }
      ],
      "source": [
        "smiles_encoder = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "23isgOJgj_H6"
      },
      "outputs": [],
      "source": [
        "smiles_encoder.encoder.layer=smiles_encoder.encoder.layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RfaEbl2o7jAv"
      },
      "outputs": [],
      "source": [
        "# smiles_arr = list(df2[\"isosmiles\"][df[\"pubchem\"]])\n",
        "smiles_arr = []\n",
        "for i in list(df[\"pubchem\"]):\n",
        "  smiles_arr.append(df2[df2[\"cid\"]==i][\"isosmiles\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NfIjoXqwWsYO"
      },
      "outputs": [],
      "source": [
        "smiles_arr = [i.item() if len(i)==1 else \"\" for i in smiles_arr]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "I_gjHemSJAvL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "fpgen = AllChem.GetRDKitFPGenerator()\n",
        "fps = []\n",
        "for i in smiles_arr[:200]:\n",
        "  a = (fpgen.GetFingerprint(Chem.MolFromSmiles(i)))\n",
        "  fps.append(np.array(a))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Pi6NiKda0FA1"
      },
      "outputs": [],
      "source": [
        "del smiles_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Y-8irptkCTGP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda:0')\n",
        "else:\n",
        "  device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wVpO2M4X-AU7"
      },
      "outputs": [],
      "source": [
        "padding = len(a)+1\n",
        "CLS = len(a)+2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MZIPysv8ViJr"
      },
      "outputs": [],
      "source": [
        "fps = [np.where(i==1) for i in fps]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "u31DBBKCAJzt"
      },
      "outputs": [],
      "source": [
        "# https://youtu.be/ug8YvZOjOCE?t=2692\n",
        "class CL(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.embeding = torch.nn.Embedding(len(a)+2, 512, padding)\n",
        "    self.transformers = torch.nn.Sequential(\n",
        "        torch.nn.TransformerEncoderLayer(512, 8, batch_first=True),\n",
        "        torch.nn.TransformerEncoderLayer(512, 8, batch_first=True),\n",
        "        torch.nn.TransformerEncoderLayer(512, 8, batch_first=True),\n",
        "        torch.nn.TransformerEncoderLayer(512, 8, batch_first=True),\n",
        "        torch.nn.TransformerEncoderLayer(512, 8, batch_first=True),\n",
        "        torch.nn.TransformerEncoderLayer(512, 8, batch_first=True),\n",
        "    )\n",
        "    self.mlp = torch.nn.Sequential(\n",
        "        torch.nn.Linear(512, 64),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(64, 32),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(32, 1),\n",
        "        torch.nn.ReLU(),\n",
        "    )\n",
        "  def forward(self, smiles):\n",
        "    return self.mlp(self.transformers(self.embeding(smiles))[:,0,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7JAFYcfLLZM",
        "outputId": "25bffe43-077d-4f45-eb00-6ade2e00dc01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwguo6358\u001b[0m (\u001b[33m3dsmile\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "pB10KKOfLYhk",
        "outputId": "686a4325-8bbb-4755-fec2-e1aed73f101f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231226_042934-216cxzfm</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/3dsmile/my-awesome-project/runs/216cxzfm' target=\"_blank\">peach-terrain-94</a></strong> to <a href='https://wandb.ai/3dsmile/my-awesome-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/3dsmile/my-awesome-project' target=\"_blank\">https://wandb.ai/3dsmile/my-awesome-project</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/3dsmile/my-awesome-project/runs/216cxzfm' target=\"_blank\">https://wandb.ai/3dsmile/my-awesome-project/runs/216cxzfm</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "run = wandb.init(\n",
        "    project=\"my-awesome-project\",\n",
        "    config={\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6syoFB_L_E2",
        "outputId": "20f54bd3-b81a-41d4-a236-47b23c5a0a3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-d42c12367c31>:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  fps_val = np.array(fps)[-100:]\n",
            "<ipython-input-18-d42c12367c31>:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  fps = np.array(fps)[:-100]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "model = CL()#.to(device)\n",
        "df[\"rt\"] = df[\"rt\"]/(max(df[\"rt\"]))\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00003)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.995)\n",
        "\n",
        "fps_val = np.array(fps)[-100:]\n",
        "RT_val = np.array(list(df[\"rt\"]))[-100:]\n",
        "\n",
        "fps = np.array(fps)[:-100]\n",
        "RT = np.array(list(df[\"rt\"]))[:-100]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "slices = list(range(0, (len(RT)), BATCH_SIZE))\n",
        "slices.append(-1)\n",
        "\n",
        "slices_val = list(range(0, (len(RT_val)), BATCH_SIZE))\n",
        "slices_val.append(-1)\n",
        "\n",
        "losses = []\n",
        "val_loss = []"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "8Nomqv-7OY68"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "5ElDz206hCEJ"
      },
      "outputs": [],
      "source": [
        "fps = [i[0] for i in fps]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dIF6bWzc9c-",
        "outputId": "c5ac1642-0212-49ea-f826-a5ec93398d6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-c063447c0de5>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  fps = np.array(fps)\n"
          ]
        }
      ],
      "source": [
        "fps = np.array(fps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Ajka9kIZnhzQ"
      },
      "outputs": [],
      "source": [
        "def pad(strs):\n",
        "  # print(strs)\n",
        "  maxlen = max([len(i) for i in strs])+1\n",
        "  strs = [[CLS]+list(i) for i in strs]\n",
        "  for i in range(len(strs)):\n",
        "    strs[i] += [padding] * (maxlen - len(strs[i]))\n",
        "  return np.array(list(strs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "jn-GWzqC0zdH",
        "outputId": "197f6f89-fbd1-472e-9387-ada8c1ebae9e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-94dfe607b3c0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "torch.tensor(pad([[1,2,3],[1,2,3]])).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "slices"
      ],
      "metadata": {
        "id": "D4zU0o8fU--U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fps.shape"
      ],
      "metadata": {
        "id": "IlKBnH9zVCcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8apVU_YwGB5w"
      },
      "outputs": [],
      "source": [
        "for epoch in range(30):\n",
        "  indices = np.arange(len(fps))\n",
        "  np.random.shuffle(indices)\n",
        "  fps = fps[indices]\n",
        "  RT = RT[indices]\n",
        "  running_loss = 0\n",
        "  for i in range(len(slices)-1):\n",
        "    X_1 = torch.tensor(pad(fps[slices[i]:slices[i+1]])).to(device)\n",
        "    Y = torch.tensor(RT[slices[i]:slices[i+1]]).to(device).unsqueeze(-1).to(torch.float32)\n",
        "    optimizer.zero_grad()\n",
        "    predicted = model(X_1)\n",
        "    loss = torch.nn.functional.mse_loss(predicted, Y)\n",
        "    # losses.append(loss.cpu())\n",
        "    running_loss+=loss.cpu()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if i%30==30-1:\n",
        "      print(\"new lr\")\n",
        "      wandb.log({\"loss\":running_loss/30,  \"lr\":optimizer.param_groups[0][\"lr\"]})\n",
        "      scheduler.step()\n",
        "      running_loss=0\n",
        "\n",
        "  # validation\n",
        "  running_loss = []\n",
        "  for i in range(len(slices_val)-1):\n",
        "    X_1 = torch.tensor(pad(fps_val[slices_val[i]:slices_val[i+1]])).to(device)\n",
        "    Y = torch.tensor(RT_val[slices_val[i]:slices_val[i+1]]).to(device).unsqueeze(-1).to(torch.float32)\n",
        "    predicted = model(X_1)\n",
        "    loss = torch.nn.functional.mse_loss(predicted, Y)\n",
        "    running_loss.append(loss.cpu().item())\n",
        "  val_loss.append(np.mean(running_loss))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Untitled123.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1q79nGQGFKL5d5Iv6SyeZ6o4VncZWNS4c\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from rdkit import Chem\n",
        "from rdkit import DataStructs\n",
        "from rdkit.Chem import AllChem\n",
        "\n",
        "df = pd.read_csv(\"/home/wg25r/SMRT_dataset.csv\", sep=\";\")\n",
        "\n",
        "df2 = pd.read_csv(\"/home/wg25r/name.csv\")\n",
        "df2 = df2[[\"isosmiles\",\"cid\"]]\n",
        "# df2.to_csv(\"name.csv\")\n",
        "\n",
        "with open(\"pid\",\"w\") as f:\n",
        "  f.write(\"\\n\".join([str(i) for i in list(df[\"pubchem\"])]))\n",
        "\n",
        "#smiles_encoder = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-base-uncased')\n",
        "import pickle\n",
        "with open(\"huggingface_transformer.pkl\", \"rb\") as f:\n",
        "        smiles_encoder = pickle.load(f)\n",
        "smiles_encoder.encoder.layer=smiles_encoder.encoder.layer\n",
        "\n",
        "# smiles_arr = list(df2[\"isosmiles\"][df[\"pubchem\"]])\n",
        "smiles_arr = []\n",
        "for i in list(df[\"pubchem\"]):\n",
        "  smiles_arr.append(df2[df2[\"cid\"]==i][\"isosmiles\"])\n",
        "\n",
        "smiles_arr = [i.item() if len(i)==1 else \"\" for i in smiles_arr]\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "fpgen = AllChem.GetRDKitFPGenerator()\n",
        "fps = []\n",
        "for i in smiles_arr:\n",
        "  a = (fpgen.GetFingerprint(Chem.MolFromSmiles(i)))\n",
        "  fps.append(np.array(a))\n",
        "\n",
        "del smiles_arr\n",
        "\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda:0')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "\n",
        "padding = len(a)+1\n",
        "CLS = len(a)+2\n",
        "\n",
        "fps = [np.where(i==1) for i in fps]\n",
        "\n",
        "# https://youtu.be/ug8YvZOjOCE?t=2692\n",
        "class CL(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.embeding = torch.nn.Embedding(len(a)+3, 512, padding)\n",
        "    self.transformers = torch.nn.TransformerEncoder(torch.nn.TransformerEncoderLayer(512,8, batch_first=True), 8)\n",
        "    #torch.nn.Sequential(\n",
        "    #    torch.nn.TransformerEncoderLayer(512, 8, batch_first=True),\n",
        "    #    torch.nn.TransformerEncoderLayer(512, 8, batch_first=True),\n",
        "    #    torch.nn.TransformerEncoderLayer(512, 8, batch_first=True),\n",
        "    #    torch.nn.TransformerEncoderLayer(512, 8, batch_first=True),\n",
        "    #)\n",
        "    self.mlp = torch.nn.Sequential(\n",
        "        torch.nn.Linear(512, 64),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(64, 32),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(32, 1),\n",
        "        torch.nn.ReLU(),\n",
        "    )\n",
        "  def forward(self, smiles):\n",
        "    return self.mlp(self.transformers(self.embeding(smiles), src_key_padding_mask=(smiles!=padding))[:,0,:])\n",
        "\n",
        "import wandb\n",
        "wandb.login()\n",
        "\n",
        "run = wandb.init(\n",
        "    project=\"my-awesome-project\",\n",
        "    config={\n",
        "    },\n",
        ")\n",
        "\n",
        "import numpy as np\n",
        "model = CL().to(device)\n",
        "df[\"rt\"] = df[\"rt\"]/(max(df[\"rt\"]))\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00003)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.995)\n",
        "\n",
        "fps_val = np.array(fps, dtype=object)[-100:]\n",
        "RT_val = np.array(list(df[\"rt\"]))[-100:]\n",
        "fps = np.array(fps, dtype=object)[:-100]\n",
        "RT = np.array(list(df[\"rt\"]))[:-100]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "slices = list(range(0, (len(RT)), BATCH_SIZE))\n",
        "slices.append(-1)\n",
        "\n",
        "slices_val = list(range(0, (len(RT_val)), BATCH_SIZE))\n",
        "slices_val.append(-1)\n",
        "\n",
        "losses = []\n",
        "val_loss = []\n",
        "\n",
        "\n",
        "fps = [i[0] for i in fps]\n",
        "fps_val = np.array([i[0] for i in fps_val], dtype=object)\n",
        "#print(fps)\n",
        "fps = np.array(fps, dtype=object)\n",
        "\n",
        "def pad(strs):\n",
        "  #print(strs)\n",
        "  maxlen = max([len(i) for i in strs])+1\n",
        "  #print(maxlen)\n",
        "  strs = [[CLS]+list(i) for i in strs]#不能在里面 cls+\n",
        "  for i in range(len(strs)):\n",
        "    strs[i] += [padding] * (maxlen - len(strs[i]))\n",
        "  return np.array(list(strs))\n",
        "\n",
        "pad([[1,2,3],[1]])\n",
        "\n",
        "for epoch in range(30):\n",
        "  indices = np.arange(len(RT))\n",
        "  np.random.shuffle(indices)\n",
        "  fps = fps[indices]\n",
        "  RT = RT[indices]\n",
        "  running_loss = 0\n",
        "  for i in range(len(slices)-1):\n",
        "    X_1 = torch.tensor(pad(fps[slices[i]:slices[i+1]])).to(device)\n",
        "    Y = torch.tensor(RT[slices[i]:slices[i+1]]).to(device).unsqueeze(-1).to(torch.float32)\n",
        "    optimizer.zero_grad()\n",
        "    predicted = model(X_1)\n",
        "    loss = torch.nn.functional.mse_loss(predicted, Y)\n",
        "    # losses.append(loss.cpu())\n",
        "    running_loss+=loss.cpu()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if i%30==30-1:\n",
        "      print(\"new lr\")\n",
        "      wandb.log({\"loss\":running_loss/30,  \"lr\":optimizer.param_groups[0][\"lr\"]})\n",
        "      scheduler.step()\n",
        "      running_loss=0\n",
        "\n",
        "  # validation\n",
        "  running_loss = []\n",
        "  for i in range(len(slices_val)-1):\n",
        "    X_1 = torch.tensor(pad(fps_val[slices_val[i]:slices_val[i+1]])).to(device)\n",
        "    Y = torch.tensor(RT_val[slices_val[i]:slices_val[i+1]]).to(device).unsqueeze(-1).to(torch.float32)\n",
        "    predicted = model(X_1)\n",
        "    loss = torch.nn.functional.mse_loss(predicted, Y)\n",
        "    running_loss.append(loss.cpu().item())\n",
        "  val_loss.append(np.mean(running_loss))\n",
        "print(val_loss)"
      ],
      "metadata": {
        "id": "zUlT9WWLiD1N"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWb1b8YSN5FytN+m0AhwyU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}