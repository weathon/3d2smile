{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNH0FrAVZzCy8tLUecHy5Lm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weathon/3d2smile/blob/main/Untitled123.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers -U\n",
        "!pip install tqdm boto3 requests regex sentencepiece sacremoses huggingface_hub\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n20yIuGF5afw",
        "outputId": "eb7b9265-e51a-4e09-b0ec-58e780ba8bcf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.34.7-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (2023.6.3)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.19.4)\n",
            "Collecting botocore<1.35.0,>=1.34.7 (from boto3)\n",
            "  Downloading botocore-1.34.7-py3-none-any.whl (11.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
            "  Downloading s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.11.17)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.7->boto3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.7->boto3) (1.16.0)\n",
            "Installing collected packages: sentencepiece, sacremoses, jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.34.7 botocore-1.34.7 jmespath-1.0.1 s3transfer-0.10.0 sacremoses-0.1.1 sentencepiece-0.1.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_ktT69Sv4Iki"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"hplc.csv\")"
      ],
      "metadata": {
        "id": "MzzAzcWx4zYw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = list(set(df[\"Column\"]))\n",
        "df[\"Column\"] = df[\"Column\"].apply(lambda x: columns.index(x))"
      ],
      "metadata": {
        "id": "1t5T0Jso462i"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smiles_encoder = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-base-uncased')"
      ],
      "metadata": {
        "id": "UnCL7WCW5FnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smiles_arr = list(df[\"SMILES\"])"
      ],
      "metadata": {
        "id": "RfaEbl2o7jAv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = list(set(\"\".join(smiles_arr)))\n",
        "tokens = dict.fromkeys(chars)\n",
        "for i, char in enumerate(chars):\n",
        "  tokens[char] = i\n",
        "reversed_mapping = {}\n",
        "for i, char in enumerate(chars):\n",
        "  reversed_mapping[i] = char\n",
        "for i, smiles in enumerate(smiles_arr):\n",
        "  smiles_arr[i] = [tokens[char] for char in smiles]"
      ],
      "metadata": {
        "id": "ATM--TJN7fEo"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars.append(\"<CLS>\")"
      ],
      "metadata": {
        "id": "pI9d6-7uAJXi"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padding = len(chars)"
      ],
      "metadata": {
        "id": "lG8jdA0ECq2R"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda:0')\n",
        "else:\n",
        "  device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "Y-8irptkCTGP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "elzXq0fiDD5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://youtu.be/ug8YvZOjOCE?t=2692\n",
        "class CL(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.smiles_encoder = smiles_encoder.to(device)\n",
        "    self.mlp = torch.nn.Sequential(torch.nn.Linear(768, 384),\n",
        "                                   torch.nn.Dropout(0.1),\n",
        "                                    torch.nn.ReLU(),\n",
        "                                    torch.nn.Linear(384, 192),\n",
        "                                    torch.nn.ReLU(),\n",
        "                                    torch.nn.Linear(192, 1))\n",
        "    self.mlp2 = torch.nn.Sequential(torch.nn.Linear(3, 6),\n",
        "                                    torch.nn.ReLU(),\n",
        "                                    torch.nn.Linear(6, 6),\n",
        "                                    torch.nn.ReLU(),\n",
        "                                    torch.nn.Linear(6, 6),\n",
        "                                    torch.nn.ReLU(),\n",
        "                                    torch.nn.Linear(6, 3),\n",
        "                                    torch.nn.ReLU(),\n",
        "                                    torch.nn.Linear(3, 1))\n",
        "\n",
        "  def forward(self, smiles, speed, portion):\n",
        "    seq = self.smiles_encoder(smiles, attention_mask=(smiles!=padding)).last_hidden_state\n",
        "    out = self.mlp(seq[:,0,:])\n",
        "    out = torch.concat((out, speed, portion),-1)\n",
        "    return self.mlp2(out)"
      ],
      "metadata": {
        "id": "u31DBBKCAJzt"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad(strs):\n",
        "  maxlen = max([len(i) for i in strs])\n",
        "  for i in range(len(strs)):\n",
        "    strs[i] += [padding] * (maxlen - len(strs[i]))\n",
        "  return strs"
      ],
      "metadata": {
        "id": "9cVN2QSmHD7T"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CL().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0003)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "speed = list(df['Speed'])\n",
        "portion = list(df[\"i-PrOH_proportion\"])\n",
        "RT = list(df[\"RT\"])\n",
        "BATCH_SIZE = 8\n",
        "slices = list(range(0, (len(df)), BATCH_SIZE))\n",
        "slices.append(-1)\n",
        "for epoch in range(30):\n",
        "  for i in range(len(slices)-1):\n",
        "    X_1 = torch.tensor(pad(smiles_arr[slices[i]:slices[i+1]])).to(device)\n",
        "    X_2 = torch.tensor(speed[slices[i]:slices[i+1]]).to(device).unsqueeze(-1)\n",
        "    X_3 = torch.tensor(portion[slices[i]:slices[i+1]]).to(device).unsqueeze(-1)\n",
        "    Y = torch.tensor(RT[slices[i]:slices[i+1]]).to(device).unsqueeze(-1)\n",
        "    optimizer.zero_grad()\n",
        "    predicted = model(X_1, X_2, X_3)\n",
        "    loss = torch.nn.functional.mse_loss(predicted, Y)\n",
        "    print(loss.item())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8apVU_YwGB5w",
        "outputId": "c1d9998f-e1d4-4dd8-ae04-3474b53209fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.087691307067871\n",
            "8.075193405151367\n",
            "9.584741592407227\n",
            "11.864588737487793\n",
            "14.657018661499023\n"
          ]
        }
      ]
    }
  ]
}