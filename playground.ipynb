{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/wg25r/with_pretrain/SwinOCSR/model/Swin-transformer-focalloss\")\n",
    "sys.path.append(\"/home/wg25r/with_pretrain/SwinOCSR/model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install timm nltk yacs deepsmiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Resuming from /home/wg25r/with_pretrain/swin_transform_focalloss.pth <=====\n",
      "Decoder: <All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/wg25r/with_pretrain/SwinOCSR/model/Swin-transformer-focalloss\")\n",
    "sys.path.append(\"/home/wg25r/with_pretrain/SwinOCSR/model/\")\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import deepsmiles\n",
    "from typing import Any, cast, Callable, List, Tuple, Union\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# from config import get_config\n",
    "from eval import Greedy_decode\n",
    "from models import build_model\n",
    "from pre_transformer import Transformer\n",
    "\n",
    "\n",
    "class FocalLossModelInference:\n",
    "    \"\"\"\n",
    "    Inference Class\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Load dictionary that maps tokens to integers\n",
    "        word_map_path = '/home/wg25r/with_pretrain/SwinOCSR/Data/500wan/500wan_shuffle_DeepSMILES_word_map'\n",
    "        self.word_map = torch.load(word_map_path)\n",
    "        self.inv_word_map = {v: k for k, v in self.word_map.items()}\n",
    "\n",
    "        # Define device, load models and weights\n",
    "        self.dev = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        # self.args, config = self.get_inference_config()\n",
    "        # self.encoder = build_model(config, tag=False)\n",
    "        self.decoder = self.build_decoder()\n",
    "        self.load_checkpoint(\"/home/wg25r/with_pretrain/swin_transform_focalloss.pth\")\n",
    "        self.decoder = self.decoder.to(self.dev).eval()\n",
    "        # self.encoder = self.encoder.to(self.dev).eval()\n",
    "\n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        \"\"\"\n",
    "        Load checkpoint and update encoder and decoder accordingly\n",
    "\n",
    "        Args:\n",
    "            checkpoint_path (str): path of checkpoint file\n",
    "        \"\"\"\n",
    "        print(f\"=====> Resuming from {checkpoint_path} <=====\")\n",
    "        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "        # encoder_msg = self.encoder.load_state_dict(checkpoint['encoder'],\n",
    "        #                                            strict=False)\n",
    "        decoder_msg = self.decoder.load_state_dict(checkpoint['decoder'],\n",
    "                                                   strict=False)\n",
    "        # print(f\"Encoder: {encoder_msg}\")\n",
    "        print(f\"Decoder: {decoder_msg}\")\n",
    "        del checkpoint\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def build_decoder(self):\n",
    "        \"\"\"\n",
    "        This method builds the Transformer decoder and returns it\n",
    "        \"\"\"\n",
    "        self.decoder_dim = 256  # dimension of decoder RNN\n",
    "        self.ff_dim = 2048\n",
    "        self.num_head = 8\n",
    "        self.dropout = 0.1\n",
    "        self.encoder_num_layer = 6\n",
    "        self.decoder_num_layer = 6\n",
    "        self.max_len = 277\n",
    "        self.decoder_lr = 5e-4\n",
    "        self.best_acc = 0.\n",
    "        return Transformer(dim=self.decoder_dim,\n",
    "                           ff_dim=self.ff_dim,\n",
    "                           num_head=self.num_head,\n",
    "                           encoder_num_layer=self.encoder_num_layer,\n",
    "                           decoder_num_layer=self.decoder_num_layer,\n",
    "                           vocab_size=len(self.word_map),\n",
    "                           max_len=self.max_len,\n",
    "                           drop_rate=self.dropout,\n",
    "                           tag=False)\n",
    "transformer_ = FocalLossModelInference().build_decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(transformer, \"/home/wg25r/with_pretrain/decoder2.pt\")\n",
    "# torch.save(transformer, \"/wg25r/home/with_pretrain/decoder2.pt\") yunkxoukunnaozi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 79])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = transformer_.decoder\n",
    "transformer(t([[2,3,4,5]]),torch.zeros(1,169,256)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 79])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_(t([[2,3,4,5]]),torch.zeros(1,256,1536)).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
