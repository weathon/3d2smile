{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSYu4cH8bEVZtnoifNfkGL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weathon/3d2smile/blob/main/finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qquj2I2RlAm"
      },
      "outputs": [],
      "source": [
        "!wget file.weasoft.com/images_rows.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget file.weasoft.com/29_4010.pt"
      ],
      "metadata": {
        "id": "3XXkX-uNSepf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://file.weasoft.com/swin_transform_focalloss.pth -nv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgMhChHvS0Nv",
        "outputId": "112bc263-2cad-45cf-8ee2-19ddbe1764a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-20 00:36:02 URL:http://file.weasoft.com/swin_transform_focalloss.pth [2555716718/2555716718] -> \"swin_transform_focalloss.pth\" [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/suanfaxiaohuo/SwinOCSR.git\n",
        "!pip install focal_loss_torch wandb\n",
        "!pip3 install deepsmiles yacs tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDo6zTHeS4Om",
        "outputId": "4b075fe1-b45f-4d61-998d-58cca96421cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepsmiles\n",
            "  Downloading deepsmiles-1.0.1-py2.py3-none-any.whl (12 kB)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from yacs) (6.0.1)\n",
            "Installing collected packages: deepsmiles, yacs\n",
            "Successfully installed deepsmiles-1.0.1 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import pandas as pd\n",
        "import os\n",
        "df = pd.read_csv(\"images_rows.csv\")\n",
        "os.makedirs(\"images\",exist_ok=1)\n",
        "def save_img(id):\n",
        "  row = df[df[\"id\"]==id]\n",
        "  print(row[\"image\"])\n",
        "  with open(f\"images/{id}.png\", \"wb\") as fh:\n",
        "      fh.write(base64.decodebytes(bytes(row[\"image\"].item().replace(\"data:image/png;base64,\",\"\"), \"utf-8\")))\n",
        "df[\"id\"].apply(save_img)"
      ],
      "metadata": {
        "id": "nuWSq0NVS8Qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"./SwinOCSR/model/Swin-transformer-focalloss\")\n",
        "sys.path.append(\"./SwinOCSR/model/\")"
      ],
      "metadata": {
        "id": "yPrlAJRlWum_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "import deepsmiles\n",
        "from typing import Any, cast, Callable, List, Tuple, Union\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "nNBpujPhUwPj"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda:0')\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "T2jSXpDvXC-J"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mod = torch.load(\"29_4010.pt\", map_location=device) #it is model not dict"
      ],
      "metadata": {
        "id": "6dA6xdVGXVog"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_pack(sequences):\n",
        "    maxlen = max(map(len, sequences))\n",
        "    batch = torch.LongTensor(len(sequences),maxlen).fill_(0)\n",
        "    for i,x in enumerate(sequences):\n",
        "        batch[i,:len(x)] = torch.LongTensor(x)\n",
        "    return batch, maxlen"
      ],
      "metadata": {
        "id": "oW55KrXRYvOe"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SMILESGenerator(torch.nn.Module):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def forward(self, image, text_in_, max_len, beam): #just changed beam=1 and it runs so beam cannot be random number???  yeah it has to been factor of 676, which is 2 2 13 13 but original paper did not use beam search\n",
        "    image_feature = self.encoder(image)\n",
        "    top_n = list([list(i) for i in torch.tensor(text_in_).repeat(beam,1).detach().cpu().numpy()])\n",
        "    # print(top_n)\n",
        "    image_feature = image_feature.repeat_interleave(beam, dim=0)#.repeat_interleave(beam)\n",
        "    for i in range(max_len):\n",
        "      if beam == 1:\n",
        "        padded_text, l = pad_pack(top_n)\n",
        "        padded_text = padded_text.to(device)\n",
        "        out = self.decoder(padded_text, image_feature, x_mask=triangle_mask(l).to(device))\n",
        "        out = out[0,-1,:]\n",
        "        next = torch.argmax(out)\n",
        "        top_n[0] += [next.detach().cpu().item()]\n",
        "        if next == 78:\n",
        "          return top_n\n",
        "        continue\n",
        "      padded_text, l = pad_pack(top_n)\n",
        "      padded_text = padded_text.to(device)\n",
        "      out = self.decoder(padded_text, image_feature, x_mask=triangle_mask(l).to(device))\n",
        "      out = out[:,-1,:]\n",
        "      next = torch.topk(torch.flatten(out), beam)\n",
        "      indices2d = np.array(np.unravel_index(next.indices.cpu().numpy(), out.shape)).T\n",
        "      new_top_n = []\n",
        "      count = 0\n",
        "      for j in indices2d:\n",
        "        beam_number = j[0]\n",
        "        char = j[1]\n",
        "        if char == 78:\n",
        "          count += 1\n",
        "          new_top_n.append(top_n[beam_number])\n",
        "        else:\n",
        "          new_top_n.append(top_n[beam_number] + [char])\n",
        "      if count == beam:\n",
        "        return new_top_n\n",
        "      top_n = new_top_n\n",
        "    return top_n"
      ],
      "metadata": {
        "id": "HDyCwVzvX1zZ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen = SMILESGenerator(mod.encoder, mod.decoder)"
      ],
      "metadata": {
        "id": "hHCjvssJYyzp"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def triangle_mask(size):\n",
        "    mask = 1- np.triu(np.ones((1, size, size)),k=1).astype('uint8')\n",
        "    mask = torch.autograd.Variable(torch.from_numpy(mask))\n",
        "    return mask"
      ],
      "metadata": {
        "id": "lS-pBOLrZYAC"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reversed_word_map = {}\n",
        "for i in transformer_.word_map.keys():\n",
        " reversed_word_map[transformer_.word_map[i]] = i"
      ],
      "metadata": {
        "id": "CF9p_SoUZkI0"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = torch.tensor(np.array(Image.open(\"Untitled.png\").resize((400,400)))).unsqueeze(0).permute(0, 3, 1, 2).to(torch.float32)"
      ],
      "metadata": {
        "id": "OaD1ppBKZwih"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\".join([reversed_word_map[i] for i in gen(test, [[77]], 500, 1)[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jVu4EaNdY1wB",
        "outputId": "9d399f9a-cff4-4770-8419-9e35f723a6f5"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start>[S-].C=S)[S+].[Cl-]<end>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    }
  ]
}