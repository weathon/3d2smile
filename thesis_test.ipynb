{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1IwXvttkcGcM7EwY_GivBMJgZjx6_xkSC",
      "authorship_tag": "ABX9TyMzQrm/MXyEMOLggF2ociHa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weathon/3d2smile/blob/main/thesis_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget file.weasoft.com/images.zip\n",
        "!wget file.weasoft.com/summary.csv\n",
        "!git clone https://github.com/suanfaxiaohuo/SwinOCSR.git\n",
        "!pip install focal_loss_torch wandb\n",
        "!pip3 install deepsmiles yacs tqdm\n",
        "!wget file.weasoft.com/model.py -O model.py\n",
        "!wget file.weasoft.com/reverse.map"
      ],
      "metadata": {
        "id": "HfdigPw-67wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip images.zip"
      ],
      "metadata": {
        "id": "gD6h4I_sC8c7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p images\n",
        "!mv *.png images\n",
        "!mv *.webp images"
      ],
      "metadata": {
        "id": "yDec1Ha0DC_b"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from model import *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoR0mYci8mLf",
        "outputId": "76db785e-af8e-4ae5-9d8d-561a33bb692b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-18 23:44:17--  http://file.weasoft.com/model.py\n",
            "Resolving file.weasoft.com (file.weasoft.com)... 149.28.13.194\n",
            "Connecting to file.weasoft.com (file.weasoft.com)|149.28.13.194|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3535 (3.5K) [text/x-python]\n",
            "Saving to: ‘model.py’\n",
            "\n",
            "\rmodel.py              0%[                    ]       0  --.-KB/s               \rmodel.py            100%[===================>]   3.45K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-18 23:44:17 (48.2 MB/s) - ‘model.py’ saved [3535/3535]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GiuKl0R76sgk"
      },
      "outputs": [],
      "source": [
        "import torch, torchvision\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda:0')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "mod = torch.load(\"drive/MyDrive/final.with.test.7.pt\", map_location=device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "class SMILESGenerator(torch.nn.Module):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def predict_next(self, i, out, beam, r):\n",
        "    reward = torch.zeros(self.top_n_p.shape)\n",
        "    if i>1:\n",
        "      for j in range(beam):\n",
        "        if self.top_n[j][-1]==78:\n",
        "          out[j]=torch.zeros(79)\n",
        "          out[j][78]=1\n",
        "          reward[j]=(0.)\n",
        "        else:\n",
        "          reward[j]=(r)\n",
        "    self.top_n_p+=reward.to(device)\n",
        "    tmp_n = self.top_n_p.repeat((79,1)).T+torch.log(out)\n",
        "    x, y = top_k_2d(tmp_n, beam)\n",
        "    new_top_n = []\n",
        "    new_top_n_p = []\n",
        "    for j in range(beam):\n",
        "      new_top_n.append(torch.cat((self.top_n[x[j]], y[j].cpu().unsqueeze(-1))))\n",
        "      new_top_n_p += [tmp_n[x[j], y[j]]]\n",
        "    self.top_n = new_top_n\n",
        "    self.top_n_p = torch.tensor(new_top_n_p).to(device)\n",
        "\n",
        "\n",
        "  def forward(self, images, text_in_, max_len, beam, r=0.05): #just changed beam=1 and it runs so beam cannot be random number???  yeah it has to been factor of 676, which is 2 2 13 13 but original paper did not use beam search\n",
        "    with torch.no_grad():\n",
        "      image_feature = []\n",
        "      for i in images:\n",
        "        mem = self.decoder.encoder(self.decoder.encoder_dim(self.encoder(i)))\n",
        "        mem = mem.repeat_interleave(beam, dim=0)\n",
        "        image_feature.append(mem)\n",
        "\n",
        "\n",
        "      self.top_n = torch.tensor(text_in_)\n",
        "      self.top_n_p = torch.tensor([0.]).to(device)\n",
        "      for i in range(max_len):\n",
        "        padded_text , l = pad_pack(self.top_n)\n",
        "        padded_text = padded_text.to(device)\n",
        "        out = []\n",
        "        for i in range(len(images)):\n",
        "          out.append(torch.nn.functional.softmax(self.decoder.decoder(padded_text, image_feature[i], x_mask=triangle_mask(l).to(device))[:,-1,:].squeeze(dim=1), dim=1))\n",
        "        out = torch.mean(torch.stack(out), dim=0)\n",
        "        self.predict_next(i, out, beam, r)\n",
        "        count = 0\n",
        "        for i in self.top_n:\n",
        "          if 78 in i:\n",
        "            count+=1\n",
        "        if count==beam:\n",
        "          return self.top_n, self.top_n_p\n",
        "      return self.top_n, self.top_n_p\n",
        "\n",
        "val_cids = [286]#, 6587, 6562, 11203]\n",
        "val_names = [i for i in os.listdir(\"./images\") if int(i.split(\"_\")[0]) in val_cids]\n",
        "\n",
        "\n",
        "mod = mod.eval()\n",
        "gen = SMILESGenerator(mod.encoder, mod.decoder)\n",
        "img1 = torch.tensor(np.array(Image.open(\"images/\"+random.choice(val_names)).convert(\"RGB\").resize((400,400)))).unsqueeze(0).permute(0,3,1,2).to(device).to(torch.float32)\n",
        "gen = gen.train(False) #forgot gen=\n",
        "res = gen.forward([img1], [[77]], 100, 10, 0)\n",
        "print()\n",
        "for i in res[0]:\n",
        "  print(converter.decode(\"\".join([reversed_word_map_[i] for i in i.numpy()])))\n",
        "print(torch.exp(res[1]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JTYjFoi-Ib_",
        "outputId": "654b6dc3-89a3-470b-9df7-b3c4032b8d77"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "<start>C(C(C(=O)[O-])O)ON<end>\n",
            "<start>C(C(C(=O)O)O)ON<end><end><end><end>\n",
            "<start>C(C(=O)O)ON<end><end><end><end><end><end><end><end>\n",
            "<start>C(C(C(=O)O)O)ON<end><end><end>\n",
            "<start>C(C(C(=O)[O-])N)ON<end>\n",
            "<start>C(C(C(=O)O)ON)ON<end><end>\n",
            "<start>C(C(C(=O)O)O)ON<end><end(>)N\n",
            "<start>C(C(=O)O)ON<end><e(nd>)O<end><end>\n",
            "<start>C(C(C(=O)O)O)ON<end><end>\n",
            "<start>C(C(=O)O)ON<end><end><end><end><end><end><end>\n",
            "tensor([0.1834, 0.1043, 0.0456, 0.0261, 0.0201, 0.0196, 0.0129, 0.0104, 0.0088,\n",
            "        0.0086])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = 1\n",
        "import deepsmiles\n",
        "from PIL import Image\n",
        "import json\n",
        "\n",
        "\n",
        "converter = deepsmiles.Converter(rings=True, branches=True)\n",
        "def triangle_mask(size):\n",
        "    mask = 1- np.triu(np.ones((1, size, size)),k=1).astype('uint8')\n",
        "    mask = torch.autograd.Variable(torch.from_numpy(mask))\n",
        "    return mask\n",
        "\n",
        "def top_k_2d(m, k):\n",
        "  values, indices = torch.topk(m.flatten(), k)\n",
        "  return indices//m.shape[1], indices%m.shape[1]\n",
        "\n",
        "def pad_pack(sequences):\n",
        "    maxlen = max(map(len, sequences))\n",
        "    batch = torch.LongTensor(len(sequences),maxlen).fill_(0)\n",
        "    for i,x in enumerate(sequences):\n",
        "        batch[i,:len(x)] = torch.LongTensor(x)\n",
        "    return batch, maxlen\n",
        "\n",
        "reversed_word_map = {}\n",
        "\n",
        "with open(\"reverse.map\",\"r\") as f:\n",
        "  reversed_word_map = json.loads(f.read())\n",
        "reversed_word_map_={}\n",
        "\n",
        "for i in reversed_word_map.keys():\n",
        "  reversed_word_map_[int(i)] = reversed_word_map[i]\n",
        ""
      ],
      "metadata": {
        "id": "SolZc6AV9J7k"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MEZJ3GDODJM0"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}