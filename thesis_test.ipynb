{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1IwXvttkcGcM7EwY_GivBMJgZjx6_xkSC",
      "authorship_tag": "ABX9TyOx5fdDNhbVqAU8DexgDvE9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weathon/3d2smile/blob/main/thesis_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget file.weasoft.com/images.zip\n",
        "!wget file.weasoft.com/summary.csv\n",
        "!git clone https://github.com/suanfaxiaohuo/SwinOCSR.git\n",
        "!pip install focal_loss_torch wandb\n",
        "!pip3 install deepsmiles yacs tqdm\n",
        "!wget file.weasoft.com/model.py -O model.py\n",
        "!wget file.weasoft.com/reverse.map"
      ],
      "metadata": {
        "id": "HfdigPw-67wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from model import *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoR0mYci8mLf",
        "outputId": "76db785e-af8e-4ae5-9d8d-561a33bb692b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-18 23:44:17--  http://file.weasoft.com/model.py\n",
            "Resolving file.weasoft.com (file.weasoft.com)... 149.28.13.194\n",
            "Connecting to file.weasoft.com (file.weasoft.com)|149.28.13.194|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3535 (3.5K) [text/x-python]\n",
            "Saving to: ‘model.py’\n",
            "\n",
            "\rmodel.py              0%[                    ]       0  --.-KB/s               \rmodel.py            100%[===================>]   3.45K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-18 23:44:17 (48.2 MB/s) - ‘model.py’ saved [3535/3535]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GiuKl0R76sgk"
      },
      "outputs": [],
      "source": [
        "import torch, torchvision\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda:0')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "mod = torch.load(\"drive/MyDrive/final.with.test.7.pt\", map_location=device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = 1\n",
        "import deepsmiles\n",
        "from PIL import Image\n",
        "import json\n",
        "\n",
        "\n",
        "converter = deepsmiles.Converter(rings=True, branches=True)\n",
        "def triangle_mask(size):\n",
        "    mask = 1- np.triu(np.ones((1, size, size)),k=1).astype('uint8')\n",
        "    mask = torch.autograd.Variable(torch.from_numpy(mask))\n",
        "    return mask\n",
        "\n",
        "def top_k_2d(m, k):\n",
        "  values, indices = torch.topk(m.flatten(), k)\n",
        "  return indices//m.shape[1], indices%m.shape[1]\n",
        "\n",
        "def pad_pack(sequences):\n",
        "    maxlen = max(map(len, sequences))\n",
        "    batch = torch.LongTensor(len(sequences),maxlen).fill_(0)\n",
        "    for i,x in enumerate(sequences):\n",
        "        batch[i,:len(x)] = torch.LongTensor(x)\n",
        "    return batch, maxlen\n",
        "\n",
        "reversed_word_map = {}\n",
        "\n",
        "with open(\"reverse.map\",\"r\") as f:\n",
        "  reversed_word_map = json.loads(f.read())\n",
        "reversed_word_map_={}\n",
        "\n",
        "for i in reversed_word_map.keys():\n",
        "  reversed_word_map_[int(i)] = reversed_word_map[i]\n",
        ""
      ],
      "metadata": {
        "id": "SolZc6AV9J7k"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "class SMILESGenerator(torch.nn.Module):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def predict_next(self, image_embeding, text_in_):\n",
        "    pass\n",
        "\n",
        "  def forward(self, images, text_in_, max_len, beam, r=0.05): #just changed beam=1 and it runs so beam cannot be random number???  yeah it has to been factor of 676, which is 2 2 13 13 but original paper did not use beam search\n",
        "    with torch.no_grad():\n",
        "      image_feature = []\n",
        "      for i in images:\n",
        "        image_feature.append(self.encoder(i))\n",
        "      image_feature = torch.stack(image_feature)\n",
        "      image_feature = image_feature.squeeze(1)\n",
        "      mem = gen.decoder.encoder(gen.decoder.encoder_dim(image_feature))\n",
        "      # mem = torch.mean(mem, dim=0)\n",
        "      # mem = mem.unsqueeze(0).repeat_interleave(beam, dim=0)\n",
        "      mem = mem.repeat_interleave(beam, dim=0)\n",
        "      top_n = torch.tensor(text_in_)\n",
        "      top_n_p = torch.tensor([0.]).to(device)\n",
        "      for i in range(max_len):\n",
        "        padded_text, l = pad_pack(top_n)\n",
        "        padded_text = padded_text.to(device)\n",
        "        out = torch.nn.functional.softmax(self.decoder.decoder(padded_text, mem, x_mask=triangle_mask(l).to(device))[:,-1,:].squeeze(dim=1), dim=1)\n",
        "        reward = torch.zeros(top_n_p.shape)\n",
        "        if i>1:\n",
        "          for j in range(beam):\n",
        "            if top_n[j][-1]==78:\n",
        "              out[j]=torch.zeros(79)\n",
        "              out[j][78]=1\n",
        "              reward[j]=(0.)\n",
        "            else:\n",
        "              reward[j]=(r)\n",
        "        top_n_p+=reward.to(device)\n",
        "        tmp_n = top_n_p.repeat((79,1)).T+torch.log(out)\n",
        "        x, y = top_k_2d(tmp_n, beam)\n",
        "        new_top_n = []\n",
        "        new_top_n_p = []\n",
        "        for j in range(beam):\n",
        "          new_top_n.append(torch.cat((top_n[x[j]], y[j].cpu().unsqueeze(-1))))\n",
        "          new_top_n_p += [tmp_n[x[j], y[j]]]\n",
        "        top_n = new_top_n\n",
        "        top_n_p = torch.tensor(new_top_n_p).to(device)\n",
        "        count = 0\n",
        "        for i in top_n:\n",
        "          if 78 in i:\n",
        "            count+=1\n",
        "        if count==beam:\n",
        "          return top_n, top_n_p\n",
        "      return top_n, top_n_p\n",
        "mod = mod.eval()\n",
        "gen = SMILESGenerator(mod.encoder, mod.decoder)\n",
        "img1 = torch.tensor(np.array(Image.open(\"111.png\").convert(\"RGB\").resize((400,400)))).unsqueeze(0).permute(0,3,1,2).to(device).to(torch.float32)\n",
        "gen = gen.train(False) #forgot gen=\n",
        "res = gen.forward([img1], [[77]], 100, 10, 0)\n",
        "print()\n",
        "for i in res[0]:\n",
        "  print(converter.decode(\"\".join([reversed_word_map_[i] for i in i.numpy()])))\n",
        "print(torch.exp(res[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JTYjFoi-Ib_",
        "outputId": "b4bc1807-f812-4953-ee92-2188ad999ebe"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "<start>COCCN1CC1<end><end><end><end><end>\n",
            "<start>COCN1CC1<end><end><end><end><end><end>\n",
            "<start>COCN1CCC1<end><end><end><end><end>\n",
            "<start>COCN1CCNC1<end><end><end><end>\n",
            "<start>COCCN1CCC1<end><end><end><end>\n",
            "<start>COCN1C=CNC1<end><end><end>\n",
            "<start>COCN1C=NC1<end><end><end><end>\n",
            "<start>COCCN1C=CNC1<end><end>\n",
            "<start>COCCN1C=CC1<end><end><end>\n",
            "<start>COCCN1C=CN=C1<end>\n",
            "tensor([0.1362, 0.1031, 0.0239, 0.0212, 0.0210, 0.0205, 0.0193, 0.0158, 0.0139,\n",
            "        0.0095])\n"
          ]
        }
      ]
    }
  ]
}