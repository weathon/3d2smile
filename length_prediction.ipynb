{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1dcI8O0OQoXZbYfvGbf7rY0IjY-0FIs1W",
      "authorship_tag": "ABX9TyO0HdG/NfpEH76C/jJ+A10O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weathon/3d2smile/blob/main/length_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepsmiles"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUFeQFw_I4Nk",
        "outputId": "f8e95c59-56a9-4bac-b447-c01c7eb27513"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deepsmiles in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiFRxOs1-Rky",
        "outputId": "a1740965-b2b7-4797-d963-02e963ecc817"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-12 04:21:38--  http://file.weasoft.com/images.zip\n",
            "Resolving file.weasoft.com (file.weasoft.com)... 149.28.13.194\n",
            "Connecting to file.weasoft.com (file.weasoft.com)|149.28.13.194|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 265877516 (254M) [application/zip]\n",
            "Saving to: ‘images.zip.3’\n",
            "\n",
            "images.zip.3          0%[                    ]       0  --.-KB/s               ^C\n",
            "--2024-02-12 04:21:39--  http://file.weasoft.com/summary.csv\n",
            "Resolving file.weasoft.com (file.weasoft.com)... 149.28.13.194\n",
            "Connecting to file.weasoft.com (file.weasoft.com)|149.28.13.194|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 326352 (319K) [text/csv]\n",
            "Saving to: ‘summary.csv.2’\n",
            "\n",
            "summary.csv.2       100%[===================>] 318.70K   399KB/s    in 0.8s    \n",
            "\n",
            "2024-02-12 04:21:40 (399 KB/s) - ‘summary.csv.2’ saved [326352/326352]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget file.weasoft.com/images.zip\n",
        "!wget file.weasoft.com/summary.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget file.weasoft.com/256.pt -O 256.pt\n",
        "!unzip images.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weVRt8uyGkJS",
        "outputId": "fea76419-8fd9-4508-eb62-32fffe98219b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-12 04:21:40--  http://file.weasoft.com/256.pt\n",
            "Resolving file.weasoft.com (file.weasoft.com)... 149.28.13.194\n",
            "Connecting to file.weasoft.com (file.weasoft.com)|149.28.13.194|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 153353860 (146M) [application/vnd.snesdev-page-table]\n",
            "Saving to: ‘256.pt’\n",
            "\n",
            "256.pt               58%[==========>         ]  85.11M  17.7MB/s    eta 4s     ^C\n",
            "Archive:  images.zip\n",
            "replace images/10952_050583472155929066.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision\n",
        "eff = torchvision.models.efficientnet_v2_s()\n",
        "mynet = eff.features\n",
        "class ImageEncoder(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.eff = mynet.to(device)\n",
        "  def forward(self, images):\n",
        "    features = self.eff(images)\n",
        "    return features"
      ],
      "metadata": {
        "id": "PxjIy7A2GqBE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda:0')\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "1daf-m55Gu3-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "molecules_rows = pd.read_csv(\"summary.csv\")"
      ],
      "metadata": {
        "id": "yUKBiGWGb0yh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_length(row):\n",
        "  return len(converter.encode(row[\"canonicalsmiles\"]))"
      ],
      "metadata": {
        "id": "zWzTVZYomjkT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import deepsmiles\n",
        "converter = deepsmiles.Converter(rings=True, branches=True)\n",
        "\n",
        "molecules_rows[\"canonicalsmiles\"] = molecules_rows.apply(get_length, axis=1, )"
      ],
      "metadata": {
        "id": "d3bW-mNEm6fC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(np.mean(molecules_rows[\"canonicalsmiles\"]), np.std(molecules_rows[\"canonicalsmiles\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31GZI-MSnyFz",
        "outputId": "1e30cf05-74e9-4cda-d26b-db0853745612"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.35820895522388 3.348875919840412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "molecules_rows[\"canonicalsmiles\"] = (molecules_rows[\"canonicalsmiles\"])/np.std(molecules_rows[\"canonicalsmiles\"])"
      ],
      "metadata": {
        "id": "rT1hH4QpngNe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random, deepsmiles, os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "cids = list(molecules_rows[\"cid\"])\n",
        "train_cids = [i for i in cids if not i in [286, 6587, 6562, 11203]]\n",
        "# val_cids = [\"a\"]\n",
        "val_cids = [286, 6587, 6562, 11203]\n",
        "\n",
        "train_names = [i for i in os.listdir(\"./images\") if int(i.split(\"_\")[0]) in train_cids]\n",
        "val_names = [i for i in os.listdir(\"./images\") if int(i.split(\"_\")[0]) in val_cids]\n",
        "from PIL import ImageOps\n",
        "BATCH_SIZE = 16\n",
        "def getitem(index, train=True):\n",
        "  global val_names, train_names\n",
        "  Y = []\n",
        "  imgs = []\n",
        "\n",
        "  # train=FalseTAMADE WEISM TRAIN = FALSE!!!guaibude bunengfanhua shouzhima ghuainbbude val namehao zuibakouke azhiqianweismkeyile? jiushiyingweimeiyouyongnamesle\n",
        "  names = train_names if train else val_names\n",
        "  start = index*BATCH_SIZE\n",
        "  end =  (index+1)*BATCH_SIZE\n",
        "  end = len(names) if end>len(names) else end\n",
        "  # print(start, end)\n",
        "  for i in range(start, end):\n",
        "\n",
        "\n",
        "    name = random.choice([i for i in names])\n",
        "    # name = random.choice([i for i in os.listdir(\"./images\")]) #shetoudzikunhzhegegebuhaishisuijidemaguaibude\n",
        "\n",
        "    img = Image.open(f\"images/{name}\").convert(\"RGB\")\n",
        "    if train:\n",
        "      img = img.rotate(random.choice([0,90,180,270]), expand=0).resize((400,400))\n",
        "      if random.random()>0.5:\n",
        "        img = ImageOps.flip(img)\n",
        "      if random.random()>0.5:\n",
        "        img = ImageOps.mirror(img)\n",
        "      img.crop((random.random()*30,random.random()*30,400-random.random()*30,400-random.random()*30))\n",
        "    img = np.array(img.resize((400,400)), dtype=\"float32\")\n",
        "    if train:\n",
        "      # img[:,:,0] *= random.random()*0.2+0.9\n",
        "      img[:,:,1] *= random.random()*0.1+0.9\n",
        "      img[:,:,2] *= random.random()*0.1+0.9\n",
        "      img[:,:,:] *= random.random()*0.1+0.8\n",
        "    img = torch.tensor(np.array(img)).permute(2, 0, 1).to(torch.float32).to(device)\n",
        "    # if train:\n",
        "    #   # img+=torch.rand((3,400,400)).to(device)*50\n",
        "    #   for _ in range(30):\n",
        "    #     x,y = int(random.random()*380),int(random.random()*380)\n",
        "    #     img[:,x:x+20, y:y+20] = torch.rand((3,20,20))*250\n",
        "#  guoranhaishiyaoqudizokunduzikoue\n",
        "    # if train:\n",
        "      # img*=torch.round(torch.tanh(5*torch.rand((3,400,400)))).to(device)\n",
        "    # print(name)\n",
        "    # print(converte//r.encode(molecules_rows[molecules_rows[\"cid\"]==int(name.split(\"_\")[0])][\"canonicalsmiles\"].item()))\n",
        "    # length = (converter.encode(molecules_rows[molecules_rows[\"cid\"]==int(name.split(\"_\")[0])][\"canonicalsmiles\"].item()))\n",
        "    length = molecules_rows[molecules_rows[\"cid\"]==int(name.split(\"_\")[0])][\"canonicalsmiles\"].item()\n",
        "    Y.append(length)\n",
        "    imgs.append(img)\n",
        "  return torch.stack(imgs), Y\n"
      ],
      "metadata": {
        "id": "CCWejvj5I0n4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Image2SMILES(torch.nn.Module):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.decoder.encoder_dim = torch.nn.Dropout(0.2)\n",
        "\n",
        "  def forward(self, image, text_in, xmask):\n",
        "    image_feature = self.encoder(image)\n",
        "    out = self.decoder(text_in, image_feature, x_mask=xmask)\n",
        "    return out\n",
        "\n",
        "\n",
        "model = torch.load(\"drive/MyDrive/encoder\", map_location=device) #it is model not dict\n"
      ],
      "metadata": {
        "id": "UcwGiXx4c-ZT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class head(torch.nn.Module):\n",
        "  def __init__(self, model):\n",
        "    super().__init__()\n",
        "    self.eff = model.eff\n",
        "    self.pooling = torch.nn.AdaptiveAvgPool2d(output_size=1)\n",
        "    self.projection = torch.nn.Linear(1280,16).to(device)\n",
        "    self.projection3 = torch.nn.Linear(16,1).to(device)\n",
        "  def forward(self, images):\n",
        "    features = self.eff(images)\n",
        "    features = torch.nn.functional.relu(self.projection(self.pooling(features).squeeze(-1).squeeze(-1)))\n",
        "    features = torch.nn.functional.relu(torch.nn.functional.dropout(self.projection3(features), 0.2))\n",
        "    # features = torch.nn.functional.relu(self.projection3(features))\n",
        "    return features"
      ],
      "metadata": {
        "id": "OTpcJJo1eUKo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mod = head(model)"
      ],
      "metadata": {
        "id": "Zd4IrcQ4emcH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val():\n",
        "  global val_names\n",
        "  np.random.shuffle(val_names)\n",
        "  running_loss = 0\n",
        "  eval_mod = mod.train(False).to(device)\n",
        "\n",
        "  image, Y = getitem(0, train=False)\n",
        "\n",
        "  image = image.to(device)\n",
        "\n",
        "\n",
        "  outputs = eval_mod(image)\n",
        "  loss = torch.nn.functional.mse_loss(outputs, torch.tensor(Y).to(device).to(torch.float32).unsqueeze(-1))\n",
        "\n",
        "  return loss.item()\n"
      ],
      "metadata": {
        "id": "p3ffOOZ7glKU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(lr, gamma, epoch, forzen, reload=False, split=1, pretrain=\"mol_80k\"):\n",
        "  global mod\n",
        "  # lr = lr*split #oh why learning rate*4 this is why it trains much better, still need nigher learning rate zuibagankouke zhege haizaizheli a a banbenwanquanluanle\n",
        "  if reload:\n",
        "    model = torch.load(\"drive/MyDrive/encoder\", map_location=device) #it is model not dict\n",
        "    mod = head(model)\n",
        "\n",
        "  losses = []\n",
        "  access = []\n",
        "  val_acc = []\n",
        "  val_loss = []\n",
        "  optimizer = torch.optim.AdamW(\n",
        "    mod.parameters(),\n",
        "    lr=lr)\n",
        "  import pylab\n",
        "  scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma)\n",
        "  running_loss = 0\n",
        "  for epoch in range(epoch):\n",
        "    np.random.shuffle(train_names)\n",
        "    mod = mod.train(True)\n",
        "\n",
        "    for i in range(len(train_names)//(BATCH_SIZE*split)):\n",
        "      if i==None:\n",
        "        continue\n",
        "      mod = mod.train(True)\n",
        "      start_index = i\n",
        "      image, Y = getitem(i, True)\n",
        "      image = image.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      outputs = mod(image)\n",
        "      loss = torch.nn.functional.mse_loss(outputs, torch.tensor(Y).to(device).to(torch.float32).unsqueeze(-1))\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      losses.append(loss.item())\n",
        "      if i%5==0:\n",
        "        a = val()\n",
        "        print(a)\n",
        "        val_loss.append(a)\n",
        "        scheduler.step()\n",
        "  pylab.plot(losses, label=\"Train\")\n",
        "  pylab.plot(np.arange(1, len(val_loss)+1)*(len(losses)/len(val_loss)),val_loss,label=\"Val\")\n",
        "  pylab.legend()\n",
        "  pylab.show()"
      ],
      "metadata": {
        "id": "5MOz-LqhgKio"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hftM_9Rzl6jo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(0.0008, 0.985, 3,  True, reload=True, pretrain=\"mol_80k\") #yeah need 0.001, if too smalel 0.001 cannot be trained duzikunduziex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "id": "OBBr3uiRg5We",
        "outputId": "e57f72c9-4a64-4ff2-e990-6c8be3763305"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.081100940704346\n",
            "2.212860584259033\n",
            "4.207893371582031\n",
            "10.90593147277832\n",
            "3.3974390029907227\n",
            "1.9236690998077393\n",
            "2.6744189262390137\n",
            "1.168203353881836\n",
            "3.1036674976348877\n",
            "2.8819310665130615\n",
            "1.5791001319885254\n",
            "1.9181008338928223\n",
            "4.506965637207031\n",
            "1.6834449768066406\n",
            "3.6150169372558594\n",
            "0.7927945852279663\n",
            "3.6349658966064453\n",
            "2.0566930770874023\n",
            "3.8292250633239746\n",
            "3.0924265384674072\n",
            "2.009941339492798\n",
            "2.035336971282959\n",
            "3.4338865280151367\n",
            "1.463343858718872\n",
            "2.0759849548339844\n",
            "3.689087152481079\n",
            "1.7098761796951294\n",
            "1.8024632930755615\n",
            "0.4445168375968933\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-2587f2acee48>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0008\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.985\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mol_80k\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#yeah need 0.001, if too smalel 0.001 cannot be trained duzikunduziex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-7191e2f7dbd1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(lr, gamma, epoch, forzen, reload, split, pretrain)\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mstart_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m       \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m       \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-ed3230890d1e>\u001b[0m in \u001b[0;36mgetitem\u001b[0;34m(index, train)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"images/{name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m       \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m270\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageOps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mrotate\u001b[0;34m(self, angle, resample, expand, center, translate, fillcolor)\u001b[0m\n\u001b[1;32m   2267\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2268\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mangle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m180\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTranspose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mROTATE_180\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2270\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mangle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m270\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexpand\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m                 return self.transpose(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(self, method)\u001b[0m\n\u001b[1;32m   2807\u001b[0m         \"\"\"\n\u001b[1;32m   2808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2809\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2810\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    874\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyaccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyaccess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpixel_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadonly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "mod = mod.cpu()\n",
        "model = model.cpu()\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "j4zfCNUWihZ9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}