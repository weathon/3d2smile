{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyP7otORghjrc4w4eXRCNQjR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weathon/3d2smile/blob/main/Test_SMILES.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnyVcrxlz1Rc",
        "outputId": "10fd78fe-2bf3-4007-f76d-22247a3461a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-11 19:58:46 URL:http://file.weasoft.com/main.pb [510999187/510999187] -> \"main.pb\" [1]\n",
            "2023-11-11 19:58:53 URL:http://file.weasoft.com/80k.csv [172176229/172176229] -> \"80k.csv\" [1]\n",
            "2023-11-11 20:00:24 URL:http://file.weasoft.com/swin_transform_focalloss.pth [2555716718/2555716718] -> \"swin_transform_focalloss.pth\" [1]\n"
          ]
        }
      ],
      "source": [
        "!wget http://file.weasoft.com/main.pb -nv\n",
        "!wget http://file.weasoft.com/80k.csv -nv\n",
        "!wget http://file.weasoft.com/swin_transform_focalloss.pth -nv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://file.weasoft.com/80k.zip"
      ],
      "metadata": {
        "id": "MfwbffN45YLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13688221-99c7-4acc-a54d-09d382de5bda"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-11 20:00:24--  http://file.weasoft.com/80k.zip\n",
            "Resolving file.weasoft.com (file.weasoft.com)... 149.28.13.194\n",
            "Connecting to file.weasoft.com (file.weasoft.com)|149.28.13.194|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3356218517 (3.1G) [application/zip]\n",
            "Saving to: ‘80k.zip’\n",
            "\n",
            "80k.zip             100%[===================>]   3.12G  24.5MB/s    in 1m 58s  \n",
            "\n",
            "2023-11-11 20:02:23 (27.0 MB/s) - ‘80k.zip’ saved [3356218517/3356218517]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q 80k.zip"
      ],
      "metadata": {
        "id": "LJzA_gW05u7v"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip3 install torch_xla"
      ],
      "metadata": {
        "id": "HVVr2SEr03VM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install deepsmiles yacs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0K1tBQ01d8r",
        "outputId": "9a689f0e-7f4b-4d51-9924-9941a528babd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepsmiles\n",
            "  Downloading deepsmiles-1.0.1-py2.py3-none-any.whl (12 kB)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from yacs) (6.0.1)\n",
            "Installing collected packages: deepsmiles, yacs\n",
            "Successfully installed deepsmiles-1.0.1 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/suanfaxiaohuo/SwinOCSR.git"
      ],
      "metadata": {
        "id": "5XIHVPNJ1lSR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fe1cf95-5a30-46ac-bcc1-3272faad4f8b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SwinOCSR'...\n",
            "remote: Enumerating objects: 453, done.\u001b[K\n",
            "remote: Counting objects: 100% (174/174), done.\u001b[K\n",
            "remote: Compressing objects: 100% (132/132), done.\u001b[K\n",
            "remote: Total 453 (delta 104), reused 77 (delta 42), pack-reused 279\u001b[K\n",
            "Receiving objects: 100% (453/453), 220.65 MiB | 19.40 MiB/s, done.\n",
            "Resolving deltas: 100% (201/201), done.\n",
            "Updating files: 100% (145/145), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision\n",
        "import os\n",
        "import numpy as np\n",
        "import pylab\n",
        "import pandas\n",
        "import sys\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "rovlreP90bP5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    HOME_DIR = \"/content\"\n",
        "else:\n",
        "    HOME_DIR = \"/arc/burst/st-dushan20-1/\""
      ],
      "metadata": {
        "id": "KA3vnh8U1Nkd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# From the SwinOCSR\n",
        "import sys\n",
        "sys.path.append(\"./SwinOCSR/model/Swin-transformer-focalloss\")\n",
        "sys.path.append(\"./SwinOCSR/model/\")\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "import deepsmiles\n",
        "from typing import Any, cast, Callable, List, Tuple, Union\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from pre_transformer import Transformer"
      ],
      "metadata": {
        "id": "au-7ZSY81Slk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# try:\n",
        "#   import torch_xla\n",
        "#   import torch_xla.core.xla_model as xm\n",
        "#   device = xm.xla_device()\n",
        "# except:\n",
        "if 1:\n",
        "  if torch.cuda.is_available():\n",
        "      device = torch.device('cuda:0')\n",
        "  else:\n",
        "      device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "BL5Wdj831EqV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLossModelInference:\n",
        "    \"\"\"\n",
        "    Inference Class\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        # Load dictionary that maps tokens to integers\n",
        "        word_map_path = './SwinOCSR/Data/500wan/500wan_shuffle_DeepSMILES_word_map'\n",
        "        self.word_map = torch.load(word_map_path)\n",
        "        self.inv_word_map = {v: k for k, v in self.word_map.items()}\n",
        "\n",
        "        # Define device, load models and weights\n",
        "        self.dev = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        # self.args, config = self.get_inference_config()\n",
        "        # self.encoder = build_model(config, tag=False)\n",
        "        self.decoder = self.build_decoder()\n",
        "        self.load_checkpoint(\"./swin_transform_focalloss.pth\")\n",
        "        self.decoder = self.decoder.to(self.dev).eval()\n",
        "        # self.encoder = self.encoder.to(self.dev).eval()\n",
        "\n",
        "    def load_checkpoint(self, checkpoint_path):\n",
        "        \"\"\"\n",
        "        Load checkpoint and update encoder and decoder accordingly\n",
        "\n",
        "        Args:\n",
        "            checkpoint_path (str): path of checkpoint file\n",
        "        \"\"\"\n",
        "        print(f\"=====> {checkpoint_path} <=====\")\n",
        "        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
        "        # encoder_msg = self.encoder.load_state_dict(checkpoint['encoder'],\n",
        "        #                                            strict=False)\n",
        "        decoder_msg = self.decoder.load_state_dict(checkpoint['decoder'],\n",
        "                                                   strict=False)\n",
        "        # print(f\"Encoder: {encoder_msg}\")\n",
        "        print(f\"Decoder: {decoder_msg}\")\n",
        "        del checkpoint\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    def build_decoder(self):\n",
        "        \"\"\"\n",
        "        This method builds the Transformer decoder and returns it\n",
        "        \"\"\"\n",
        "        self.decoder_dim = 256  # dimension of decoder RNN\n",
        "        self.ff_dim = 2048\n",
        "        self.num_head = 8\n",
        "        self.dropout = 0.1\n",
        "        self.encoder_num_layer = 6\n",
        "        self.decoder_num_layer = 6\n",
        "        self.max_len = 277\n",
        "        self.decoder_lr = 5e-4\n",
        "        self.best_acc = 0.\n",
        "        return Transformer(dim=self.decoder_dim,\n",
        "                           ff_dim=self.ff_dim,\n",
        "                           num_head=self.num_head,\n",
        "                           encoder_num_layer=self.encoder_num_layer,\n",
        "                           decoder_num_layer=self.decoder_num_layer,\n",
        "                           vocab_size=len(self.word_map),\n",
        "                           max_len=self.max_len,\n",
        "                           drop_rate=self.dropout,\n",
        "                           tag=False)\n",
        "transformer_ = FocalLossModelInference()\n",
        "transformer = transformer_.build_decoder().decoder\n",
        "\n",
        "converter = deepsmiles.Converter(rings=True, branches=True)\n",
        "\n",
        "\n",
        "def str_to_vector(s: str)->list:\n",
        "  return [transformer_.word_map[i] for i in converter.encode(s)]\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "csv = pd.read_csv(\"./80k.csv\")\n",
        "cids = csv[\"cid\"]\n",
        "csv.columns\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWiFh9bA1wUV",
        "outputId": "4e7e73e5-c7ca-47e6-f0ca-19102630931e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====> ./swin_transform_focalloss.pth <=====\n",
            "Decoder: <All keys matched successfully>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['cid', 'cmpdname', 'cmpdsynonym', 'mw', 'mf', 'polararea', 'complexity',\n",
              "       'xlogp', 'heavycnt', 'hbonddonor', 'hbondacc', 'rotbonds', 'inchi',\n",
              "       'isosmiles', 'canonicalsmiles', 'inchikey', 'iupacname', 'exactmass',\n",
              "       'monoisotopicmass', 'charge', 'covalentunitcnt', 'isotopeatomcnt',\n",
              "       'totalatomstereocnt', 'definedatomstereocnt', 'undefinedatomstereocnt',\n",
              "       'totalbondstereocnt', 'definedbondstereocnt', 'undefinedbondstereocnt',\n",
              "       'pclidcnt', 'gpidcnt', 'gpfamilycnt', 'neighbortype', 'meshheadings',\n",
              "       'annothits', 'annothitcnt', 'aids', 'cidcdate', 'sidsrcname', 'depcatg',\n",
              "       'annotation'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ys = {}\n",
        "invalid_cids = []\n",
        "for i in cids.values:\n",
        "    tmp = str_to_vector(csv[csv[\"cid\"] == i][\"canonicalsmiles\"].values[0])\n",
        "    if not tmp == None:\n",
        "      Ys[i] = tmp\n",
        "    else:\n",
        "      invalid_cids.append(i)\n",
        "\n",
        "print(\"OOHH\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9L9d_nQJ2V_m",
        "outputId": "a770c635-9ce1-4725-a6c9-18ec5213b4e8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOHH\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install focal_loss_torch wandb"
      ],
      "metadata": {
        "id": "3qbQiwEx6iXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from focal_loss.focal_loss import FocalLoss\n",
        "m = torch.nn.Softmax(dim=-1)\n",
        "lf = FocalLoss(gamma=2, ignore_index=0)#torch.nn.CrossEntropyLoss(label_smoothing=0.1, reduction=\"none\")\n",
        "def loss_fn(pred, truth):\n",
        "  pred = m(pred)\n",
        "  l = lf(pred, truth)\n",
        "  return l\n",
        "\n",
        "\n",
        "def mask_acc(pred, truth):\n",
        "    pred = torch.argmax(pred, -1)\n",
        "    mask = truth != 0\n",
        "    match_case = truth == pred\n",
        "    return torch.sum(mask*match_case)/torch.sum(mask)\n",
        "\n",
        "\n",
        "\n",
        "import pickle\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "files = os.listdir(f\"./rendered/\")\n",
        "files = [i for i in files if len(i)<=40]\n",
        "import multiprocessing, threading\n",
        "#https://stackoverflow.com/questions/48822463/how-to-use-pytorch-multiprocessing\n",
        "from torch.multiprocessing import Process, Queue, Pool\n",
        "import time\n",
        "buffer = Queue(maxsize=10) #need maxsize=10, otherwise put will also block\n",
        "start_index = 0\n",
        "import cv2\n",
        "def process_single(arg):\n",
        "    # print(arg)\n",
        "    _, start_index = arg\n",
        "    index = start_index + _\n",
        "    try:\n",
        "      id = int(files[index].split(\"_\")[0])\n",
        "    except:\n",
        "      return\n",
        "    img = np.array(Image.open(f\"{HOME_DIR}/rendered/{files[index]}\")) #cannot read image? quota reached?\n",
        "    return img, [77] + Ys[id], Ys[id] + [78]\n",
        "\n",
        "#pool = Pool()\n",
        "\n",
        "\n",
        "#read all images\n",
        "images_warehouse = []\n",
        "index = 0\n",
        "import time\n",
        "t0 = time.time()\n",
        "import os, psutil\n",
        "process = psutil.Process()\n"
      ],
      "metadata": {
        "id": "Vt1J6ydd6cht"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# reset"
      ],
      "metadata": {
        "id": "_LPAoMbiFdb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "example_in = Image.open(\"./rendered/6912034_0.jpg\")\n",
        "example_out = csv[csv[\"cid\"]==6912034][\"canonicalsmiles\"].values[0]\n",
        "\n",
        "# In[15]:\n",
        "\n",
        "\n",
        "example_out = str_to_vector(example_out)\n",
        "\n",
        "\n",
        "torch.permute(torch.tensor(np.expand_dims(example_in, 0).astype(\"float32\")), (0,3,1,2)).size()\n",
        "\n",
        "\n",
        "t = torch.randn(1,64,400,400)\n",
        "torch.flatten(t)\n",
        "torch.flatten(t, start_dim=2,end_dim=3).shape\n",
        "\n",
        "\n",
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "    return pos * angle_rates\n",
        "\n",
        "import numpy as np\n",
        "def positional_encoding_1d(position, d_model):\n",
        "    angle_rads = get_angles(\n",
        "        np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model\n",
        "    )\n",
        "\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "    return pos_encoding\n",
        "\n",
        "\n",
        "def positional_encoding_2d(row, col, d_model):\n",
        "    assert d_model % 2 == 0\n",
        "    row_pos = np.repeat(np.arange(row), col)[:, np.newaxis]\n",
        "    col_pos = np.repeat(np.expand_dims(np.arange(col), 0), row, axis=0).reshape(-1, 1)\n",
        "\n",
        "    angle_rads_row = get_angles(\n",
        "        row_pos, np.arange(d_model // 2)[np.newaxis, :], d_model // 2\n",
        "    )\n",
        "    angle_rads_col = get_angles(\n",
        "        col_pos, np.arange(d_model // 2)[np.newaxis, :], d_model // 2\n",
        "    )\n",
        "\n",
        "    angle_rads_row[:, 0::2] = np.sin(angle_rads_row[:, 0::2])\n",
        "    angle_rads_row[:, 1::2] = np.cos(angle_rads_row[:, 1::2])\n",
        "    angle_rads_col[:, 0::2] = np.sin(angle_rads_col[:, 0::2])\n",
        "    angle_rads_col[:, 1::2] = np.cos(angle_rads_col[:, 1::2])\n",
        "    pos_encoding = np.concatenate([angle_rads_row, angle_rads_col], axis=1)[\n",
        "        np.newaxis, ...\n",
        "    ]\n",
        "    return pos_encoding\n",
        "\n",
        "eff = torchvision.models.efficientnet_v2_l(weights='DEFAULT')\n",
        "mynet = eff.features\n",
        "class ImageEncoder(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.eff = mynet.to(device)\n",
        "    self.projection = torch.nn.Linear(1280,256).to(device)\n",
        "  def forward(self, images):\n",
        "    features = self.eff(images)\n",
        "    features = torch.flatten(features, start_dim=2, end_dim=3)\n",
        "    features = torch.permute(features, (0, 2, 1))\n",
        "    return self.projection(features)\n",
        "\n",
        "try:\n",
        "  # https://stackoverflow.com/questions/70508960/how-to-free-gpu-memory-in-pytorch\n",
        "  import gc\n",
        "\n",
        "  model.cpu()\n",
        "  gen.cpu()\n",
        "  del model, gen\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "except:\n",
        "  pass\n",
        "\n",
        "encoder = ImageEncoder()\n",
        "\n",
        "for p in transformer.parameters():\n",
        "  p.requires_grad = False\n",
        "\n",
        "\n",
        "# In[45]:\n",
        "# from another paper\n",
        "def pad_pack(sequences):\n",
        "    maxlen = max(map(len, sequences))\n",
        "    batch = torch.LongTensor(len(sequences),maxlen).fill_(0)\n",
        "    for i,x in enumerate(sequences):\n",
        "        batch[i,:len(x)] = torch.LongTensor(x)\n",
        "    return batch, maxlen\n",
        "\n",
        "# https://github.com/suanfaxiaohuo/SwinOCSR/blob/main/model/Swin-transformer-focalloss/pre_transformer.py#L95\n",
        "def triangle_mask(size):\n",
        "    mask = 1- np.triu(np.ones((1, size, size)),k=1).astype('uint8')\n",
        "    mask = torch.autograd.Variable(torch.from_numpy(mask))\n",
        "    return mask\n",
        "\n",
        "\n",
        "class Image2SMILES(torch.nn.Module):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def forward(self, image, text_in, xmask):\n",
        "    #padded_text, maxlen = pad_pack(text_in)\n",
        "    #padded_text = padded_text.to(device)\n",
        "    # image = torch.permute(torch.tensor(np.array(image)), (0,3,1,2))\n",
        "    image_feature = self.encoder(image)\n",
        "    out = self.decoder(text_in, image_feature, x_mask=xmask)#triangle_mask(maxlen).to(device))\n",
        "    return out\n",
        "\n",
        "# In[46]:\n",
        "\n",
        "def softmax(x):\n",
        "        t = np.exp(x)\n",
        "        return t/np.sum(t)\n",
        "class SMILESGenerator(torch.nn.Module):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def forward(self, image, text_in, max_len):\n",
        "    image_feature = self.encoder(image)\n",
        "    conf = 1\n",
        "    for i in range(max_len):\n",
        "      padded_text = pad_pack(text_in)[0]\n",
        "      padded_text = padded_text.to(device)\n",
        "      out = self.decoder(padded_text, image_feature, x_mask=triangle_mask(len(text_in)).to(device))\n",
        "\n",
        "      # next = torch.sort(out, descending=True)[0][0,0].cpu().detach().numpy()[0]\n",
        "      next = torch.argmax(out[0][-1]).cpu().detach().item()\n",
        "      if(next==78):\n",
        "        break\n",
        "      # print(next)\n",
        "      # conf = conf * softmax(torch.sort(out, descending=True)[0][0].cpu().detach().numpy())[0][0]\n",
        "\n",
        "      text_in[0] += [next]\n",
        "      # print(text_in)\n",
        "    return text_in[0]\n",
        "\n",
        "\n",
        "model = Image2SMILES(encoder, transformer)\n",
        "model.load_state_dict(torch.load(\"./main.pb\", map_location=device))\n",
        "gen = SMILESGenerator(model.encoder, model.decoder)\n",
        "\n",
        "model = model.to(device)\n",
        "gen = gen.to(device)\n",
        "\n",
        "\n",
        "def softmax(x):\n",
        "  t = np.exp(x)\n",
        "  return t/np.sum(t)\n"
      ],
      "metadata": {
        "id": "DwuU7Rrp53Sw"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reversed_word_map = {}\n",
        "for i in transformer_.word_map.keys():\n",
        " reversed_word_map[transformer_.word_map[i]] = i"
      ],
      "metadata": {
        "id": "ztNaZ26N7wOR"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# run"
      ],
      "metadata": {
        "id": "GsmOz0DXCH4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "print(\"Started\")\n",
        "\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "   lr=0.0003)\n",
        "\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99987)\n",
        "\n",
        "\n",
        "loss_list = []\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "def getitem(i):\n",
        " imgs = []\n",
        " ti = []\n",
        " to = []\n",
        " for i in range(i, i+BATCH_SIZE):\n",
        "    index = i\n",
        "    try:\n",
        "      id = int(files[index].split(\"_\")[0])\n",
        "    except:\n",
        "      return\n",
        "    try:\n",
        "     img = np.array(Image.open(f\"./rendered/{files[index]}\")) #cannot read image? quota reached?\n",
        "     imgs.append(img)\n",
        "     ti.append([77] + Ys[id])\n",
        "     to.append(Ys[id] + [78])\n",
        "    except:\n",
        "     pass\n",
        " return torch.tensor(np.array(imgs), dtype=torch.float32), ti, to\n",
        "\n",
        "Test = True\n",
        "if Test:\n",
        "  model.train(False)\n",
        "  gen.train(False)\n",
        "  running_loss = 0\n",
        "  last_loss = 0\n",
        "  for i in range(10, len(files)//BATCH_SIZE-1):\n",
        "    start_index = i * BATCH_SIZE\n",
        "    Xs_img = []\n",
        "    Xs_text = []\n",
        "    y = []\n",
        "\n",
        "    image, text_in, text_out = getitem(start_index)\n",
        "    image = image.to(device)\n",
        "    text_out = pad_pack(text_out)[0].to(device)\n",
        "    padded_x = pad_pack(text_in)\n",
        "    xmask = triangle_mask(padded_x[1]).to(device)\n",
        "    image = torch.permute(image, (0, 3, 1, 2))\n",
        "    text_in = padded_x[0].to(device)\n",
        "\n",
        "    outputs = model(image, text_in, xmask)[0].cpu().detach().numpy()\n",
        "    print(\"Teacher forcing output:\\t\\t\", \"\".join([reversed_word_map[np.argmax(i)] for i in outputs]))\n",
        "    print(\"Token by Token Output:\\t\\t\", \"\".join([reversed_word_map[i] for i in gen(image, [[77]], 8)]))\n",
        "    print(\"Correct output:\\t\\t\\t\", \"\".join([reversed_word_map[i] for i in text_out[0].detach().cpu().numpy()]))\n",
        "    print()\n",
        "else:\n",
        "  for epoch in range(30):\n",
        "    image = Xs_img.to(device) #mutli process cannot use cuda so moved here\n",
        "    image = torch.permute(image, (0, 3, 1, 2))\n",
        "    text_out = pad_pack(text_out)[0].to(device)\n",
        "    padded_x = pad_pack(text_in)\n",
        "\n",
        "    xmask = triangle_mask(padded_x[1]).to(device)\n",
        "    text_in = padded_x[0].to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(image, text_in, xmask)\n",
        "    loss = loss_fn(outputs, text_out)\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    if i%100==99:\n",
        "        wandb.log({\"loss\": running_loss/100, \"acc\":mask_acc(outputs.detach(), text_out), \"lr\": optimizer.param_groups[0]['lr']})\n",
        "        running_loss = 0.\n",
        "    if i%10 == 9:\n",
        "        scheduler.step()\n",
        "\n",
        "    if i == 10:\n",
        "        model.train(False)\n",
        "        for ii in range(0,10):\n",
        "            Xs_img, text_in, text_out = getitem(ii * BATCH_SIZE)\n",
        "\n",
        "            image = Xs_img.to(device) #mutli process cannot use cuda so moved here\n",
        "            image = torch.permute(image, (0, 3, 1, 2))\n",
        "            text_out = pad_pack(text_out)[0].to(device)\n",
        "            padded_x = pad_pack(text_in)\n",
        "            xmask = triangle_mask(padded_x[1]).to(device)\n",
        "            text_in = padded_x[0].to(device)\n",
        "            outputs = model(image, text_in, xmask)\n",
        "            loss = loss_fn(outputs, text_out)\n",
        "            wandb.log({\"val_loss\": loss, \"val_acc\":mask_acc(outputs.detach(), text_out)})\n",
        "        model.train(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0ox3u4v-69bA",
        "outputId": "6aea1abf-de0b-4119-c5ec-324c0bb364d9"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started\n",
            "Teacher forcing output:\t\t C=CC=CC=C6C=O)C=CO6)))))OO))O<end>\n",
            "Token by Token Output:\t\t <start>CC=CCCC=\n",
            "Correct output:\t\t C=CC=CC=C6C=O)C=CO6))))))O))O<end>\n",
            "\n",
            "Teacher forcing output:\t\t CC=CC=NC=CC=CC=C%106))))))))N<end>\n",
            "Token by Token Output:\t\t <start>CCCCC=C=\n",
            "Correct output:\t\t CC=CC=NC=CC=CC=C%106))))))))N<end>\n",
            "\n",
            "Teacher forcing output:\t\t CCCF)F)F))NC=CN=CC=C6<end><end><end><end><end><end>\n",
            "Token by Token Output:\t\t <start>CCC=CCC=\n",
            "Correct output:\t\t CCCF)F)F))NC=CN=CC=C6<end><pad><pad><pad><pad><pad>\n",
            "\n",
            "Teacher forcing output:\t\t CSC=NC=CS5)C=O)NC=N6<end><end><end><end><end><end><end><end><end>\n",
            "Token by Token Output:\t\t <start>CC=NC=NC\n",
            "Correct output:\t\t CSC=NC=CS5)C=O)NC=N6<end><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "Teacher forcing output:\t\t CCCCC=O)C=C6CCC%%10=O<end><end><end><end><end><end><end>\n",
            "Token by Token Output:\t\t <start>CCCC=O)C\n",
            "Correct output:\t\t CCCCC=O)C=C6CCCC%10=O<end><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "Teacher forcing output:\t\t C=CCCCC=O)O))))N))F<end><end><end><end><end><end><end><end><end><end><end><end>\n",
            "Token by Token Output:\t\t <start>CC=CC=N5\n",
            "Correct output:\t\t C=CCCCC=O)O))))N))F<end><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "Teacher forcing output:\t\t CC#CCCC#CC<end><end><end><end><end><end><end><end><end><end><end><end><end><end><end>\n",
            "Token by Token Output:\t\t <start>CC=CCC=O\n",
            "Correct output:\t\t CC#CCCC#CC<end><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "Teacher forcing output:\t\t CNC=CC=O)NC6=O))C)))C=O)))N<end>\n",
            "Token by Token Output:\t\t <start>CCCCC=C=\n",
            "Correct output:\t\t CNC=CC=O)NC6=O))C)))C=O)))N<end>\n",
            "\n",
            "Teacher forcing output:\t\t CCCC=C5C=CC=C6)Br)))))))N<end>\n",
            "Token by Token Output:\t\t <start>CCC=NC=C\n",
            "Correct output:\t\t CCCC=C5C=CC=C6)Br)))))))N<end>\n",
            "\n",
            "Teacher forcing output:\t\t CCC)CCCCCC6=O))O3))C<end><end><end><end><end><end><end><end>\n",
            "Token by Token Output:\t\t <start>CCC=O)CC\n",
            "Correct output:\t\t CCC)CCCCCC6=O))O3))C<end><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "Teacher forcing output:\t\t CCCCCCCCCCCO<end><end><end><end><end><end><end><end><end><end><end><end><end><end><end>\n",
            "Token by Token Output:\t\t <start>CC=CC=C=\n",
            "Correct output:\t\t CCCCCCCCCCCO<end><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "Teacher forcing output:\t\t CCC=CC=CC=N6))))C<end><end><end><end><end><end><end><end><end>\n",
            "Token by Token Output:\t\t <start>CCC=CC=C\n",
            "Correct output:\t\t CCC=CC=CC=N6))))C<end><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "Teacher forcing output:\t\t CCOC=O)C=CN=CN5)))N<end><end><end><end><end><end><end><end><end><end><end><end><end><end>\n",
            "Token by Token Output:\t\t <start>CCC=O)C=\n",
            "Correct output:\t\t CCOC=O)C=CN=CN5)))N<end><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "Teacher forcing output:\t\t CCCC=O)C=CC<end><end><end><end><end><end><end><end><end><end><end><end>\n",
            "Token by Token Output:\t\t <start>CCC=NC=C\n",
            "Correct output:\t\t CCCC=O)C=CC<end><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "Teacher forcing output:\t\t COC=CC=CC=C6))[N+]=O)[O-])))Cl<end>\n",
            "Token by Token Output:\t\t <start>CCC=O)NC\n",
            "Correct output:\t\t COC=CC=CC=C6))[N+]=O)[O-])))Cl<end>\n",
            "\n",
            "Teacher forcing output:\t\t CCC)C)OC=O)NC)O<end>))<end><end><end><end><end><end><end>\n",
            "Token by Token Output:\t\t <start>CCCC)CN=\n",
            "Correct output:\t\t CCC)C)OC=O)NC)O<end><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "Teacher forcing output:\t\t CCCC)OC=O)CC)C)C<end>)<end><end><end><end><end><end><end><end><end><end><end>\n",
            "Token by Token Output:\t\t <start>CCCC=CC=\n",
            "Correct output:\t\t CCCC)OC=O)CC)C)C<end><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "Teacher forcing output:\t\t COC=CC=CC#N))C#N<end>)<end><end><end><end><end><end><end><end><end><end><end><end><end>\n",
            "Token by Token Output:\t\t <start>CCC=CC=C\n",
            "Correct output:\t\t COC=CC=CC#N))C#N<end><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "Teacher forcing output:\t\t CC=CSC=N5)C=O<end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end>\n",
            "Token by Token Output:\t\t <start>CC=C)C=O\n",
            "Correct output:\t\t CC=CSC=N5)C=O<end><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "Teacher forcing output:\t\t CCCS)SCC<end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end>\n",
            "Token by Token Output:\t\t <start>CCC=N)NC\n",
            "Correct output:\t\t CCCS)SCC<end><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "Teacher forcing output:\t\t CCCC=O)NCC7))CCO<end><end><end><end><end><end><end>\n",
            "Token by Token Output:\t\t <start>CCCCC=O)\n",
            "Correct output:\t\t CCCC=O)NCC7))CCO<end><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "Teacher forcing output:\t\t CCCCC=C6)))CO)CCO<end><end><end><end><end><end><end><end><end><end><end><end><end><end>\n",
            "Token by Token Output:\t\t <start>CCC=NC=C\n",
            "Correct output:\t\t CCCCC=C6)))CO))CO<end><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "Teacher forcing output:\t\t CCCCC=CC=CC=C6))O)))O<end><end>\n",
            "Token by Token Output:\t\t <start>CCCC=O)C\n",
            "Correct output:\t\t CCCCC=CC=CC=C6))O)))O<end><pad>\n",
            "\n",
            "Teacher forcing output:\t\t C=CC=NC=CN5C=C9))))C##N<end>\n",
            "Token by Token Output:\t\t <start>CCCCC=O)\n",
            "Correct output:\t\t C=CC=NC=CN5C=C9))))CC#N<end>\n",
            "\n",
            "Teacher forcing output:\t\t CCCCC=CC=CC=O)O))))))O<end>)<end><end>\n",
            "Token by Token Output:\t\t <start>CCCCC=C=\n",
            "Correct output:\t\t CCCCC=CC=CC=O)O))))))O<end><pad><pad><pad>\n",
            "\n",
            "Teacher forcing output:\t\t CCCOCC6)F)F)))F)F<end>))<end><end><end><end>\n",
            "Token by Token Output:\t\t <start>CC=CC=C=\n",
            "Correct output:\t\t CCCOCC6)F)F)))F)F<end><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "Teacher forcing output:\t\t CCSCCN6CC#N<end><end><end><end><end><end><end><end><end><end><end><end><end><end><end>\n",
            "Token by Token Output:\t\t <start>CC=NCCCC\n",
            "Correct output:\t\t CCSCCN6CC#N<end><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "Teacher forcing output:\t\t CC=O)O))NN<end><end><end><end><end><end><end><end><end><end><end><end><end>\n",
            "Token by Token Output:\t\t <start>CC=CC=CC\n",
            "Correct output:\t\t CC=O)O))NN<end><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "Teacher forcing output:\t\t CC[N+]CC3))CCO.[Cl-]<end>..\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-a18cd87a5062>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Teacher forcing output:\\t\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreversed_word_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Token by Token Output:\\t\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreversed_word_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m77\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Correct output:\\t\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreversed_word_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-54-fdde4a21bf12>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image, text_in, max_len)\u001b[0m\n\u001b[1;32m    131\u001b[0m       \u001b[0mpadded_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m       \u001b[0mpadded_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpadded_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtriangle_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m       \u001b[0;31m# next = torch.sort(out, descending=True)[0][0,0].cpu().detach().numpy()[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-54-fdde4a21bf12>\u001b[0m in \u001b[0;36mtriangle_mask\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m# https://github.com/suanfaxiaohuo/SwinOCSR/blob/main/model/Swin-transformer-focalloss/pre_transformer.py#L95\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtriangle_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mones\u001b[0;34m(shape, dtype, order, like)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ones_with_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0mmultiarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'unsafe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g_wAGXecFShP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}