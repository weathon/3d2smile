{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1QyswmFpDOafdCi7qQgarEsNtNefHhs-D",
      "authorship_tag": "ABX9TyPWm9iyYaI/w5TGFKBt63v0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weathon/3d2smile/blob/main/Untitled84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgd4WeOQYMUf"
      },
      "outputs": [],
      "source": [
        "# https://www.tensorflow.org/tutorials/text/image_captioning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Definition"
      ],
      "metadata": {
        "id": "oNge4RCnZDsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pylab"
      ],
      "metadata": {
        "id": "mgQYZ2-pYlwz"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CHANNELS = [64, 64, 128, 256, 512]\n",
        "RES_NUMBER = 4\n",
        "LSTM_UNITS = 1024\n",
        "EMBEDING_DIM =1024\n",
        "HEADS = 8\n",
        "DECODER_NUM = 2"
      ],
      "metadata": {
        "id": "n83-IihPSwkW"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetBlock(tf.keras.layers.Layer):\n",
        "  def __init__(self, channel1, channel2, name):\n",
        "    super().__init__(name=name)\n",
        "    self.Conv2D = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(channel1, (3,3), padding=\"same\", strides = 2),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.ReLU(),\n",
        "        tf.keras.layers.Conv2D(channel2, (3,3), padding=\"same\"),\n",
        "        tf.keras.layers.BatchNormalization()\n",
        "    ])\n",
        "    self.project =  tf.keras.layers.Conv2D(channel2, (1,1), name=\"image_projection\", strides = 2)\n",
        "    self.relu = tf.keras.layers.ReLU()\n",
        "\n",
        "  def call(self, images):\n",
        "    x = self.Conv2D(images)\n",
        "    images = self.project(images)\n",
        "    return self.relu(x+images)\n",
        "\n",
        "class PosEncoding(tf.keras.layers.Layer):\n",
        "  def __init__(self, max_length):\n",
        "    super().__init__()\n",
        "    self.max_length = max_length\n",
        "    self.Embeding =  tf.keras.layers.Embedding(max_length, EMBEDING_DIM, input_length=max_length)\n",
        "\n",
        "  def call(self, x):\n",
        "    tags = tf.range(self.max_length)\n",
        "    return self.Embeding(tags[tf.newaxis,:]) + x\n",
        "\n",
        "\n",
        "class ImageEncoder(tf.keras.layers.Layer):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv2D_7 = tf.keras.layers.Conv2D(CHANNELS[0], (7, 7), padding=\"same\", strides = 2)\n",
        "    self.pooling = tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides=2)\n",
        "    self.ResBlocks = []\n",
        "    for i in range(RES_NUMBER):\n",
        "      self.ResBlocks.append(ResNetBlock(CHANNELS[i+1], CHANNELS[i+1]*2, name=f\"resblock_{i}\"))\n",
        "    self.flatten = tf.keras.layers.Reshape((49,1024))\n",
        "    self.img_pos_encoding = PosEncoding(49)\n",
        "    self.attention = tf.keras.layers.Attention()\n",
        "\n",
        "  def call(self, images):\n",
        "    images = self.conv2D_7(images)\n",
        "    images = self.pooling(images)\n",
        "    for block in self.ResBlocks:\n",
        "      images = block(images)\n",
        "    images = self.flatten(images)\n",
        "    images = self.img_pos_encoding(images)\n",
        "    return self.attention([images, images, images])\n",
        "\n",
        "  # def model(self):\n",
        "  #     x = tf.keras.layers.Input(shape=(400, 400, 3))\n",
        "  #     return tf.keras.Model(inputs=[x], outputs=self.call(x))\n",
        "  # https://stackoverflow.com/questions/55235212/model-summary-cant-print-output-shape-while-using-subclass-model"
      ],
      "metadata": {
        "id": "sV6crwYoZeM-"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AddNorm(tf.keras.layers.Layer):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.norm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "  def call(self, x, y):\n",
        "    return self.norm(x+y)\n",
        "\n",
        "\n",
        "class TextEncoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_token, max_length, name=\"\"):\n",
        "    if name == \"\":\n",
        "      super().__init__()\n",
        "    else:\n",
        "      super().__init__(name=name)\n",
        "    self.num_token, self.max_length = num_token, max_length\n",
        "    self.pos_encoding = PosEncoding(max_length) #added one above already\n",
        "    self.Embeding =  tf.keras.layers.Embedding(num_token, EMBEDING_DIM, input_length=max_length)\n",
        "    self.attention = tf.keras.layers.MultiHeadAttention(HEADS, 1024, dropout=0.1)\n",
        "    self.add_and_norm = AddNorm()\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.Embeding(x)\n",
        "    x = self.pos_encoding(x)\n",
        "    attention_score = self.attention(x, x, use_causal_mask=1)\n",
        "    return self.add_and_norm(attention_score, x)\n",
        "\n",
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_token):\n",
        "    super().__init__()\n",
        "    self.MultiHeadAttention = tf.keras.layers.MultiHeadAttention(HEADS, 1024, dropout=0.1)\n",
        "\n",
        "  def call(self, image_features, texts):\n",
        "    return self.MultiHeadAttention(value=image_features, query=texts)\n",
        "\n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_token, max_length):\n",
        "    super().__init__()\n",
        "    self.TextEncoder = TextEncoder(num_token, max_length)\n",
        "\n",
        "    # input = tf.keras.layers.Input(shape=(400, 400, 3))\n",
        "    self.ImageEncoder = ImageEncoder()\n",
        "    #  tf.keras.Model(inputs=[input], outputs=ImageEncoder().call(input))\n",
        "\n",
        "    # # input2 = tf.keras.layers.Input(shape=(100, 500))\n",
        "    self.TextEncoder = TextEncoder(100, 500)\n",
        "    # #tf.keras.Model(inputs=[input2], outputs=TextEncoder(100, 500).call(input2))\n",
        "    # input2 = tf.keras.layers.Input(shape=(500))\n",
        "    # self.TextEncoder = tf.keras.Model(inputs=[input2], outputs=TextEncoder(100, 500).call(input2))\n",
        "\n",
        "    self.CrossAttentions = []\n",
        "    self.add_and_norm1s = []\n",
        "    self.add_and_norm2s = []\n",
        "    self.MLPs = []\n",
        "\n",
        "    for i in range(DECODER_NUM):\n",
        "      self.CrossAttention.append(CrossAttention(num_token))\n",
        "      self.add_and_norm1.append(AddNorm())\n",
        "      self.add_and_norm2.append(AddNorm())\n",
        "      self.MLP.append(tf.keras.Sequential([\n",
        "          tf.keras.layers.Dense(2048, activation=\"relu\"),\n",
        "          tf.keras.layers.Dense(1024, activation=\"relu\"),\n",
        "          tf.keras.layers.Dropout(0.1)], name=\"MLP\"))\n",
        "\n",
        "    self.DenseWithSoftmax = tf.keras.Sequential(\n",
        "        [tf.keras.layers.Dense(num_token),\n",
        "        tf.keras.layers.Dense(num_token, activation=\"softmax\")], name=\"linear_and_softmax\")\n",
        "\n",
        "  def call(self, images, texts):\n",
        "    images = self.ImageEncoder(images)\n",
        "    texts = self.TextEncoder(texts)\n",
        "    for i in range(DECODER_NUM):\n",
        "      features = self.CrossAttention(images, texts)\n",
        "      features = self.add_and_norm1(features, texts)\n",
        "      text = self.add_and_norm2(self.MLP(features), features)\n",
        "    return self.DenseWithSoftmax(text)\n",
        "\n"
      ],
      "metadata": {
        "id": "tczJDrZZSC2S"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Decoder(100, 500)\n",
        "input1 = tf.keras.layers.Input(shape=(400, 400, 3))\n",
        "input2 = tf.keras.layers.Input(shape=(500)) #input is NOT onehot\n",
        "model =  tf.keras.Model(inputs=[input1, input2], outputs=model.call(input1, input2))\n",
        "model.summary(expand_nested=1)\n",
        "tf.keras.utils.plot_model(model, expand_nested=1)"
      ],
      "metadata": {
        "id": "dpLbgQ5_I4D0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Pre-processing\n"
      ],
      "metadata": {
        "id": "Iz5-CVdmY_wd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text"
      ],
      "metadata": {
        "id": "YkRZRNPrbStr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not \"80k\" in os.listdir(\"/content\"):\n",
        "  os.system(\"cp drive/MyDrive/80k.zip .\")\n",
        "  os.system(\"cp drive/MyDrive/80k.csv .\")\n",
        "  os.system(\"unzip 80k.zip\")"
      ],
      "metadata": {
        "id": "hOwm8VyqREw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "ids = [i.split(\"_\")[0] for i in os.listdir(\"rendered\")]\n",
        "\n",
        "with open(\"ids.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(list(set(ids))))"
      ],
      "metadata": {
        "id": "Bz4JFumTXAFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "zZ7uMiqXYeD4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv = pd.read_csv(\"80k.csv\")"
      ],
      "metadata": {
        "id": "oqsoszhZYwl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0G560I1Y9h2",
        "outputId": "673471e0-e6c3-473e-a493-81a33228deb4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['cid', 'cmpdname', 'cmpdsynonym', 'mw', 'mf', 'polararea', 'complexity',\n",
              "       'xlogp', 'heavycnt', 'hbonddonor', 'hbondacc', 'rotbonds', 'inchi',\n",
              "       'isosmiles', 'canonicalsmiles', 'inchikey', 'iupacname', 'exactmass',\n",
              "       'monoisotopicmass', 'charge', 'covalentunitcnt', 'isotopeatomcnt',\n",
              "       'totalatomstereocnt', 'definedatomstereocnt', 'undefinedatomstereocnt',\n",
              "       'totalbondstereocnt', 'definedbondstereocnt', 'undefinedbondstereocnt',\n",
              "       'pclidcnt', 'gpidcnt', 'gpfamilycnt', 'neighbortype', 'meshheadings',\n",
              "       'annothits', 'annothitcnt', 'aids', 'cidcdate', 'sidsrcname', 'depcatg',\n",
              "       'annotation'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cids = csv[\"cid\"]"
      ],
      "metadata": {
        "id": "-9v5LW9JZJh_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ys = {}\n",
        "for i in cids.values:\n",
        "  Ys[i] = csv[csv[\"cid\"] == i][\"canonicalsmiles\"].values[0]"
      ],
      "metadata": {
        "id": "fLjqnnz9ZZ4A"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ys_in = {}\n",
        "Ys_out = {}\n",
        "for i in Ys.keys():\n",
        "  Ys_in[i] = \"ðŸ˜˜\" + Ys[i]\n",
        "  Ys_out[i] = Ys[i] + \"ðŸ˜¢\""
      ],
      "metadata": {
        "id": "w0PT5TEVaJih"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image"
      ],
      "metadata": {
        "id": "7En_bh63bZLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# No processing at this point"
      ],
      "metadata": {
        "id": "grstWebkbbyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline"
      ],
      "metadata": {
        "id": "Gz8AJu5MbeST"
      }
    }
  ]
}