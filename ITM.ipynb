{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHM8dCseTz/YIoSJ78QOo/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weathon/3d2smile/blob/main/ITM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yx9l03x7a-vq"
      },
      "outputs": [],
      "source": [
        "# !pip install rdkit deepsmiles\n",
        "# !pip3 install torchinfo\n",
        "# !pip install tqdm boto3 requests regex sentencepiece sacremoses huggingface_hub\n",
        "# !wget http://file.weasoft.com/80k.csv\n",
        "# !pip install transformers -U"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rdkit\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "import deepsmiles\n",
        "import numpy as np\n",
        "import pylab\n",
        "converter = deepsmiles.Converter(rings=True, branches=True)\n",
        "def deepsmiles_to_img(ds):\n",
        "   img = np.array(Draw.MolToImage(Chem.MolFromSmiles(converter.decode(ds)), size=(400,400)).convert(\"L\", dither=None).convert(\"RGB\"))\n",
        "   img = np.where(img<253, 0, 1) * img\n",
        "   return img\n",
        "\n",
        "def smiles_to_img(smiles):\n",
        "  return deepsmiles_to_img(converter.encode(smiles))\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda:0')\n",
        "else:\n",
        "  device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "pjjuor65bCnW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "csv = pandas.read_csv(\"80k.csv\")\n",
        "\n",
        "smiles_arr = []\n",
        "for smiles in csv['canonicalsmiles']:\n",
        "  smiles_arr.append(converter.encode(smiles))"
      ],
      "metadata": {
        "id": "y8M7a7upbE11"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smiles_encoder = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYz9P5RHbbBZ",
        "outputId": "b20e1030-7310-4bd1-b958-1999aa9b1696"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "image_encoder = torchvision.models.swin_s(weights='DEFAULT')"
      ],
      "metadata": {
        "id": "crK6sA47cbPl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchinfo\n",
        "image_encoder.norm = torch.nn.Identity()\n",
        "image_encoder.permute = torch.nn.Identity()\n",
        "image_encoder.avgpool = torch.nn.Identity()\n",
        "image_encoder.flatten = torch.nn.Flatten(-3, -2)\n",
        "\n",
        "image_encoder.head = torch.nn.Identity()\n",
        "# torchinfo.summary(image_encoder, input_size=(1, 3, 400, 400))"
      ],
      "metadata": {
        "id": "apZrQET3cjEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_encoder(torch.rand(1, 3, 400, 400)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJ6-GN65fXRB",
        "outputId": "7919452c-5769-4ab6-b7c7-1a8aadd0d4f0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 169, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smiles_encoder.pooler = torch.nn.Identity()\n",
        "# torchinfo.summary(smiles_encoder, input_data=torch.ones(1, 128, dtype=torch.int32))"
      ],
      "metadata": {
        "id": "sebmyOu_eASp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smiles_encoder(torch.zeros(1,128, dtype=torch.int32)).last_hidden_state.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-IBYvN4fdY4",
        "outputId": "e25ebbc8-fe58-43f1-9d79-de2774695321"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 128, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = list(set(\"\".join(smiles_arr)))\n",
        "tokens = dict.fromkeys(chars)\n",
        "for i, char in enumerate(chars):\n",
        "  tokens[char] = i\n",
        "reversed_mapping = {}\n",
        "for i, char in enumerate(chars):\n",
        "  reversed_mapping[i] = char\n",
        "for i, smiles in enumerate(smiles_arr):\n",
        "  smiles_arr[i] = [tokens[char] for char in smiles]"
      ],
      "metadata": {
        "id": "VjcR4BCQbjNg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://youtu.be/ug8YvZOjOCE?t=2692\n",
        "class CL(torch.nn.Module):\n",
        "  def __init__(self, maxlen):\n",
        "    super().__init__()\n",
        "    self.image_encoder = image_encoder\n",
        "    self.smiles_encoder = smiles_encoder\n",
        "    self.smiles_proj = torch.nn.Linear(768, 512)\n",
        "    self.pos1 = torch.nn.Embedding(13*13, 768)\n",
        "    self.pos2 = torch.nn.Embedding(maxlen, 768)\n",
        "    self.modal = torch.nn.Embedding(2, 768)\n",
        "    self.i_begin = torch.nn.Embedding(2, 768)\n",
        "    self.t_begin = torch.nn.Embedding(2, 768)\n",
        "\n",
        "  def forward(self, image, smiles):\n",
        "    image_embedding = self.image_encoder(image)\n",
        "    smiles_embedding = self.smiles_encoder(smiles, attention_mask=(smiles!=30)).last_hidden_state\n",
        "    pos_image = self.pos1(torch.arange(13*13))\n",
        "    m_i = self.modal(torch.zeros(image_embedding.shape[1], dtype=torch.int32))\n",
        "    image_embedding = image_embedding + pos_image + m_i\n",
        "    pos_txt = self.pos2(torch.arange(smiles_embedding.shape[1]))\n",
        "    m_t = self.modal(torch.ones(smiles_embedding.shape[1], dtype=torch.int32))\n",
        "    smiles_embedding = smiles_embedding + pos_txt + m_t\n",
        "\n",
        "    seq = torch.cat([image_embedding, smiles_embedding], dim=1)\n",
        "    print(seq.shape)"
      ],
      "metadata": {
        "id": "eE41myMyfKzX"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CL(512)(torch.rand(2, 3, 400, 400), torch.zeros(2,128, dtype=torch.int32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2u3r8oegxE4",
        "outputId": "c577feb7-3c9f-441d-873a-05a945b4858d"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 768])\n",
            "torch.Size([2, 297, 768])\n"
          ]
        }
      ]
    }
  ]
}