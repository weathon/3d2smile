{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyPUS/0vF/8wYbOgQeGpUm8v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weathon/3d2smile/blob/main/ITM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yx9l03x7a-vq"
      },
      "outputs": [],
      "source": [
        "# !pip install rdkit deepsmiles\n",
        "# !pip3 install torchinfo\n",
        "# !pip install tqdm boto3 requests regex sentencepiece sacremoses huggingface_hub\n",
        "# !wget http://file.weasoft.com/80k.csv\n",
        "# !pip install transformers -U"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rdkit\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "import deepsmiles\n",
        "import numpy as np\n",
        "import pylab\n",
        "converter = deepsmiles.Converter(rings=True, branches=True)\n",
        "def deepsmiles_to_img(ds):\n",
        "   img = np.array(Draw.MolToImage(Chem.MolFromSmiles(converter.decode(ds)), size=(400,400)).convert(\"L\", dither=None).convert(\"RGB\"))\n",
        "   img = np.where(img<253, 0, 1) * img\n",
        "   return img\n",
        "\n",
        "def smiles_to_img(smiles):\n",
        "  return deepsmiles_to_img(converter.encode(smiles))\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda:0')\n",
        "else:\n",
        "  device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "pjjuor65bCnW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "csv = pandas.read_csv(\"80k.csv\")\n",
        "\n",
        "smiles_arr = []\n",
        "for smiles in csv['canonicalsmiles']:\n",
        "  smiles_arr.append(converter.encode(smiles))"
      ],
      "metadata": {
        "id": "y8M7a7upbE11"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smiles_encoder = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYz9P5RHbbBZ",
        "outputId": "aa4e43ad-3eec-4644-9d2a-f9846aee322b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "image_encoder = torchvision.models.swin_s(weights='DEFAULT')"
      ],
      "metadata": {
        "id": "crK6sA47cbPl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchinfo\n",
        "image_encoder.norm = torch.nn.Identity()\n",
        "image_encoder.permute = torch.nn.Identity()\n",
        "image_encoder.avgpool = torch.nn.Identity()\n",
        "image_encoder.flatten = torch.nn.Flatten(-3, -2)\n",
        "\n",
        "image_encoder.head = torch.nn.Identity()\n",
        "# torchinfo.summary(image_encoder, input_size=(1, 3, 400, 400))"
      ],
      "metadata": {
        "id": "apZrQET3cjEA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_encoder(torch.rand(1, 3, 400, 400)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJ6-GN65fXRB",
        "outputId": "f5540070-2493-414e-eae6-6957b6375156"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 169, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smiles_encoder.pooler = torch.nn.Identity()\n",
        "# torchinfo.summary(smiles_encoder, input_data=torch.ones(1, 128, dtype=torch.int32))"
      ],
      "metadata": {
        "id": "sebmyOu_eASp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smiles_encoder(torch.zeros(1,128, dtype=torch.int32)).last_hidden_state.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-IBYvN4fdY4",
        "outputId": "bb61633e-706b-44e7-e3fa-3f83ebc7ed16"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 128, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = list(set(\"\".join(smiles_arr)))\n",
        "tokens = dict.fromkeys(chars)\n",
        "for i, char in enumerate(chars):\n",
        "  tokens[char] = i\n",
        "reversed_mapping = {}\n",
        "for i, char in enumerate(chars):\n",
        "  reversed_mapping[i] = char\n",
        "for i, smiles in enumerate(smiles_arr):\n",
        "  smiles_arr[i] = [tokens[char] for char in smiles]"
      ],
      "metadata": {
        "id": "VjcR4BCQbjNg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://youtu.be/ug8YvZOjOCE?t=2692\n",
        "class CL(torch.nn.Module):\n",
        "  def __init__(self, maxlen):\n",
        "    super().__init__()\n",
        "    self.image_encoder = image_encoder.to(device)\n",
        "    self.smiles_encoder = smiles_encoder.to(device)\n",
        "    self.smiles_proj = torch.nn.Linear(768, 512).to(device)\n",
        "    self.pos1 = torch.nn.Embedding(13*13, 768).to(device)\n",
        "    self.pos2 = torch.nn.Embedding(maxlen, 768).to(device)\n",
        "    self.modal = torch.nn.Embedding(2, 768).to(device)\n",
        "    self.i_begin = torch.nn.Embedding(1, 768).to(device)\n",
        "    self.t_begin = torch.nn.Embedding(1, 768).to(device)\n",
        "    self.fusion = torch.nn.Sequential(\n",
        "        torch.nn.TransformerEncoderLayer(d_model=768, nhead=8, dim_feedforward=512, dropout=0.1, batch_first=True).to(device),\n",
        "        torch.nn.TransformerEncoderLayer(d_model=768, nhead=8, dim_feedforward=512, dropout=0.1, batch_first=True).to(device),\n",
        "        torch.nn.TransformerEncoderLayer(d_model=768, nhead=8, dim_feedforward=512, dropout=0.1, batch_first=True).to(device),\n",
        "        torch.nn.TransformerEncoderLayer(d_model=768, nhead=8, dim_feedforward=512, dropout=0.1, batch_first=True).to(device),\n",
        "    ).to(device)\n",
        "    self.head = torch.nn.Linear(768, 30).to(device)\n",
        "  def forward(self, image, smiles):\n",
        "    # print(self.i_begin(torch.tensor(0)).unsqueeze(0).unsqueeze(0).repeat(image.shape[0],1,1).shape)\n",
        "    image_embedding = self.image_encoder(image)\n",
        "    smiles_embedding = self.smiles_encoder(smiles, attention_mask=(smiles!=30)).last_hidden_state\n",
        "    pos_image = self.pos1(torch.arange(13*13).to(device))\n",
        "    m_i = self.modal(torch.zeros(image_embedding.shape[1], dtype=torch.int32).to(device))\n",
        "    image_embedding = image_embedding + pos_image + m_i\n",
        "    pos_txt = self.pos2(torch.arange(smiles_embedding.shape[1]).to(device))\n",
        "    m_t = self.modal(torch.ones(smiles_embedding.shape[1], dtype=torch.int32).to(device))\n",
        "    smiles_embedding = smiles_embedding + pos_txt + m_t\n",
        "    seq = torch.cat([self.i_begin(torch.tensor(0).to(device)).unsqueeze(0).unsqueeze(0).repeat(image.shape[0],1,1), image_embedding, self.i_begin(torch.tensor(0).to(device)).unsqueeze(0).unsqueeze(0).repeat(image.shape[0],1,1), smiles_embedding], dim=1)\n",
        "    src_mask = torch.cat([torch.ones(image.shape[0], image_embedding.shape[1]+2).to(device),(smiles!=30)], dim=-1)\n",
        "    for i in self.fusion:\n",
        "      seq = i(seq, src_key_padding_mask =src_mask) #src_mask should be the key mask duzikuneyunedkoukekun\n",
        "    return self.head(seq[:,image_embedding.shape[1]+2:,:])\n",
        "# CL(512)(torch.rand(2, 3, 400, 400), torch.zeros(2,128, dtype=torch.int32))"
      ],
      "metadata": {
        "id": "eE41myMyfKzX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reversed_mapping[29] = \"\"\n",
        "reversed_mapping[30] = \"\""
      ],
      "metadata": {
        "id": "XGu1I4aHwC8S"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "model = CL(max([len(i) for i in smiles_arr])).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0003)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99987)\n",
        "L = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
        "\n",
        "n = 4\n",
        "losses = []\n",
        "for EPOCH in range(30):\n",
        "  for i in range(0, len(smiles_arr), n):\n",
        "    images_list = []\n",
        "    smiles_list = []\n",
        "    masked_smiles_list = []\n",
        "    maxlen = 0\n",
        "    for j in range(n):\n",
        "        image = deepsmiles_to_img(\"\".join([reversed_mapping[_] for _ in smiles_arr[i+j]]))\n",
        "        image = torch.tensor(image).permute(2,0,1)\n",
        "        images_list.append(image)\n",
        "        smiles_list.append(smiles_arr[i+j])\n",
        "        masked_smiles_list.append(smiles_arr[i+j][:])\n",
        "        masked_smiles_list[-1][random.randint(0, len(masked_smiles_list))] = 31\n",
        "        masked_smiles_list[-1][random.randint(0, len(masked_smiles_list))] = 31\n",
        "        masked_smiles_list[-1][random.randint(0, len(masked_smiles_list))] = 31\n",
        "        maxlen = max(maxlen, len(smiles_arr[i+j]))\n",
        "\n",
        "    for j in range(n):\n",
        "      smiles_list[j] += [30] * (maxlen - len(smiles_list[j]))\n",
        "      masked_smiles_list[j] += [30] * (maxlen - len(masked_smiles_list[j]))\n",
        "\n",
        "    images_list = torch.stack(images_list).to(torch.float32)\n",
        "    smiles_list = torch.tensor(smiles_list, dtype=torch.int32).to(device)\n",
        "    masked_smiles_list = torch.tensor(masked_smiles_list, dtype=torch.int32).to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(images_list.to(device), masked_smiles_list.to(device)).permute(0,2,1)\n",
        "    # print(logits.shape, smiles_list.shape)\n",
        "    loss = torch.mean(L(logits, smiles_list.to(torch.int64))*(masked_smiles_list==31))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    losses.append(loss.detach().cpu().item())\n",
        "    # print(i)\n",
        "    if i%500 == 0:\n",
        "      pylab.plot(losses)\n",
        "      pylab.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "BmA7hk-dpFr4",
        "outputId": "8ab1eb63-a248-4f14-9c31-09ebc0e9e569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLr9c00V6Bh6",
        "outputId": "3c3e7660-cb9f-4856-a95a-303df7976d96"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 21, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(masked_smiles_list==31).repeat(1,1,30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWGo84HO50t3",
        "outputId": "792b0746-ff31-4885-ea2a-43b1f8429a6a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ True,  True, False,  ..., False, False, False],\n",
              "         [False,  True,  True,  ..., False, False, False],\n",
              "         [ True,  True, False,  ..., False, False, False],\n",
              "         [ True,  True, False,  ..., False, False, False]]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smiles_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvcEs0pr5WPa",
        "outputId": "f9ea3574-1154-45c1-e8aa-9c0c1cc8ef16"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[14, 19, 14, 14, 19, 14, 14, 19, 14,  6, 13, 13,  3, 14, 14, 14, 14, 19,\n",
              "          4, 13,  4],\n",
              "        [14, 14, 14, 14, 14, 14,  4,  6, 13, 14,  4, 13, 13, 13,  4, 13, 13,  4,\n",
              "         13, 13,  4],\n",
              "        [14, 14, 19,  4, 13, 14,  4, 14, 10, 19,  4, 30, 30, 30, 30, 30, 30, 30,\n",
              "         30, 30, 30],\n",
              "        [14, 14,  4, 14, 14, 10, 14, 22, 13, 13, 14, 22, 30, 30, 30, 30, 30, 30,\n",
              "         30, 30, 30]], device='cuda:0', dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_smiles_list==31"
      ],
      "metadata": {
        "id": "xTRj5X3941cJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.nn.functional.binary_cross_entropy_with_logits(torch.tensor([0.1,0.2,0.3,0.4]), torch.tensor([1.0,1,1,1]))"
      ],
      "metadata": {
        "id": "B4RIb6H9xVu8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}